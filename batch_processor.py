"""
××¢×‘×“ Batch ×œ×¢×™×‘×•×“ ××¨×•×‘×” ×§×‘×¦×™×
Batch Processor for Multiple Files
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Callable, Any
import re
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
from database import db
from services import code_service as code_processor
from cache_manager import cache
from html import escape as html_escape
import tempfile
import subprocess
import os

logger = logging.getLogger(__name__)

@dataclass
class BatchJob:
    """×¢×‘×•×“×ª batch"""
    job_id: str
    user_id: int
    operation: str
    files: List[str]
    status: str = "pending"  # pending, running, completed, failed
    progress: int = 0
    total: int = 0
    results: Dict[str, Any] = None
    error_message: str = ""
    start_time: float = 0
    end_time: float = 0
    
    def __post_init__(self):
        if self.results is None:
            self.results = {}
        if self.total == 0:
            self.total = len(self.files)

class BatchProcessor:
    """××¢×‘×“ batch ×œ×¤×¢×•×œ×•×ª ×¢×œ ××¨×•×‘×” ×§×‘×¦×™×"""
    
    def __init__(self):
        self.max_workers = 3  # ××¡×¤×¨ threads ××§×¡×™××œ×™ ×›×“×™ ×œ×× ×•×¢ "×¡×™×•× ××™×™×“×™" ×œ× ×¨×™××œ×™
        self.max_concurrent_jobs = 3  # ××¡×¤×¨ ×¢×‘×•×“×•×ª batch ×‘×•-×–×× ×™×ª
        self.active_jobs: Dict[str, BatchJob] = {}
        self.job_counter = 0
    
    def create_job(self, user_id: int, operation: str, files: List[str]) -> str:
        """×™×¦×™×¨×ª ×¢×‘×•×“×ª batch ×—×“×©×”"""
        self.job_counter += 1
        job_id = f"batch_{user_id}_{self.job_counter}_{int(time.time())}"
        
        job = BatchJob(
            job_id=job_id,
            user_id=user_id,
            operation=operation,
            files=files
        )
        
        self.active_jobs[job_id] = job
        logger.info(f"× ×•×¦×¨×” ×¢×‘×•×“×ª batch: {job_id} ×¢× {len(files)} ×§×‘×¦×™×")
        
        return job_id
    
    async def process_files_batch(self, job_id: str, operation_func: Callable, **kwargs) -> BatchJob:
        """×¢×™×‘×•×“ batch ×©×œ ×§×‘×¦×™×"""
        if job_id not in self.active_jobs:
            raise ValueError(f"×¢×‘×•×“×ª batch {job_id} ×œ× × ××¦××”")
        
        job = self.active_jobs[job_id]
        job.status = "running"
        job.start_time = time.time()
        
        try:
            # ×¢×™×‘×•×“ ×‘parallel ×¢× ThreadPoolExecutor
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # ×™×¦×™×¨×ª futures ×œ×›×œ ×§×•×‘×¥
                future_to_file = {
                    executor.submit(operation_func, job.user_id, file_name, **kwargs): file_name
                    for file_name in job.files
                }
                
                # ×¢×™×‘×•×“ ×”×ª×•×¦××•×ª ×›×©×”×Ÿ ××•×›× ×•×ª
                for future in as_completed(future_to_file):
                    file_name = future_to_file[future]
                    
                    try:
                        result = future.result()
                        # ×§×‘×¢ ×”×¦×œ×—×” ×œ×•×’×™×ª ×œ×¤×™ ×ª×•×¦××ª ×”×¤×•× ×§×¦×™×” (×œ××©×œ is_valid)
                        success_flag = True
                        if isinstance(result, dict) and ('is_valid' in result):
                            success_flag = bool(result.get('is_valid'))
                        job.results[file_name] = {
                            'success': success_flag,
                            'result': result
                        }
                    except Exception as e:
                        job.results[file_name] = {
                            'success': False,
                            'error': str(e)
                        }
                        logger.error(f"×©×’×™××” ×‘×¢×™×‘×•×“ {file_name}: {e}")
                    
                    # ×¢×“×›×•×Ÿ progress
                    job.progress += 1
                    logger.debug(f"Job {job_id}: {job.progress}/{job.total} completed")
                    # ×”×•×¡×¤×ª ×“×™×œ×™×™ ×§×˜×Ÿ ×›×“×™ ×œ××¤×©×¨ ×—×•×•×™×™×ª ×”×ª×§×“××•×ª ×××™×ª×™×ª (×•×œ× "×¡×™×™× ×‘×©× ×™×™×”")
                    # × ××•×š ××¡×¤×™×§ ×›×“×™ ×œ× ×œ×¢×›×‘ ××©××¢×•×ª×™×ª, ××š ×™×•×¦×¨ ×ª×—×•×©×” ×¨×™××œ×™×ª ×‘-UI
                    try:
                        time.sleep(0.05)
                    except Exception:
                        pass
            
            job.status = "completed"
            job.end_time = time.time()
            
            # ×—×™×©×•×‘ ×¡×˜×˜×™×¡×˜×™×§×•×ª
            successful = sum(1 for r in job.results.values() if r['success'])
            failed = job.total - successful
            
            logger.info(f"×¢×‘×•×“×ª batch {job_id} ×”×•×©×œ××”: {successful} ×”×¦×œ×™×—×•, {failed} × ×›×©×œ×•")
            
        except Exception as e:
            job.status = "failed"
            job.error_message = str(e)
            job.end_time = time.time()
            logger.error(f"×¢×‘×•×“×ª batch {job_id} × ×›×©×œ×”: {e}")
        
        return job
    
    async def analyze_files_batch(self, user_id: int, file_names: List[str]) -> str:
        """× ×™×ª×•×— batch ×©×œ ×§×‘×¦×™×"""
        job_id = self.create_job(user_id, "analyze", file_names)
        
        def analyze_single_file(user_id: int, file_name: str) -> Dict[str, Any]:
            """× ×™×ª×•×— ×§×•×‘×¥ ×™×—×™×“"""
            try:
                file_data = db.get_latest_version(user_id, file_name)
                if not file_data:
                    return {'error': '×§×•×‘×¥ ×œ× × ××¦×'}
                
                code = file_data['code']
                language = file_data['programming_language']
                
                # × ×™×ª×•×— ×”×§×•×“ (×¢××•×§ ×™×•×ª×¨ ×¢×‘×•×¨ ×§×‘×¦×™× ×’×“×•×œ×™×)
                analysis = code_processor.analyze_code(code, language)
                # ×¡×™××•×œ×¦×™×™×ª ×–××Ÿ ×¢×™×‘×•×“ ×¨×™××œ×™: 1ms ×œ×›×œ 500 ×ª×•×•×™×, ×¢×“ 150ms
                try:
                    delay = min(max(len(code) / 500_000.0, 0.02), 0.15)
                    time.sleep(delay)
                except Exception:
                    pass
                
                return {
                    'lines': len(code.split('\n')),
                    'chars': len(code),
                    'language': language,
                    'analysis': analysis
                }
                
            except Exception as e:
                return {'error': str(e)}
        
        # ×”×¨×¦×” ×‘×¨×§×¢ ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×œ×•×œ××” ×”×¨××©×™×ª
        asyncio.create_task(self.process_files_batch(job_id, analyze_single_file))
        return job_id
    
    async def validate_files_batch(self, user_id: int, file_names: List[str]) -> str:
        """×‘×“×™×§×ª ×ª×§×™× ×•×ª batch ×©×œ ×§×‘×¦×™×"""
        job_id = self.create_job(user_id, "validate", file_names)
        
        def _run_local_cmd(args_list, cwd: str, timeout_sec: int = 20) -> Dict[str, Any]:
            try:
                completed = subprocess.run(
                    args_list,
                    cwd=cwd,
                    capture_output=True,
                    text=True,
                    timeout=timeout_sec
                )
                output = (completed.stdout or "") + (completed.stderr or "")
                return {"returncode": completed.returncode, "output": output.strip()}
            except subprocess.TimeoutExpired as e:
                return {"returncode": 124, "output": "Timeout"}
            except FileNotFoundError:
                return {"returncode": 127, "output": "Tool not installed"}
            except Exception as e:
                return {"returncode": 1, "output": str(e)}

        def _advanced_python_checks(temp_dir: str, filename: str) -> Dict[str, Any]:
            results: Dict[str, Any] = {}
            # Prefer project configs if present in temp_dir (copied beforehand)
            results["flake8"] = _run_local_cmd(["flake8", filename], temp_dir)
            results["mypy"] = _run_local_cmd(["mypy", filename], temp_dir)
            results["bandit"] = _run_local_cmd(["bandit", "-q", "-r", filename], temp_dir)
            results["black"] = _run_local_cmd(["black", "--check", filename], temp_dir)
            return results

        def _copy_lint_configs(temp_dir: str) -> None:
            """Copy lint/type/security config files into temp_dir if they exist in project root."""
            project_root = os.getcwd()
            configs = [
                (os.path.join(project_root, ".flake8"), os.path.join(temp_dir, ".flake8")),
                (os.path.join(project_root, "pyproject.toml"), os.path.join(temp_dir, "pyproject.toml")),
                (os.path.join(project_root, "mypy.ini"), os.path.join(temp_dir, "mypy.ini")),
                (os.path.join(project_root, "bandit.yaml"), os.path.join(temp_dir, "bandit.yaml")),
                # JS/TS linters/formatters
                (os.path.join(project_root, ".eslintrc.json"), os.path.join(temp_dir, ".eslintrc.json")),
                (os.path.join(project_root, ".eslintrc.js"), os.path.join(temp_dir, ".eslintrc.js")),
                (os.path.join(project_root, "package.json"), os.path.join(temp_dir, "package.json")),
                (os.path.join(project_root, ".prettierrc"), os.path.join(temp_dir, ".prettierrc")),
                (os.path.join(project_root, "prettier.config.js"), os.path.join(temp_dir, "prettier.config.js")),
                (os.path.join(project_root, "tsconfig.json"), os.path.join(temp_dir, "tsconfig.json")),
                # YAML/Docker/Semgrep
                (os.path.join(project_root, ".yamllint"), os.path.join(temp_dir, ".yamllint")),
                (os.path.join(project_root, ".hadolint.yaml"), os.path.join(temp_dir, ".hadolint.yaml")),
                (os.path.join(project_root, ".semgrep.yml"), os.path.join(temp_dir, ".semgrep.yml")),
                (os.path.join(project_root, ".semgrep.yaml"), os.path.join(temp_dir, ".semgrep.yaml")),
            ]
            for src, dst in configs:
                try:
                    if os.path.isfile(src):
                        with open(src, "rb") as fsrc, open(dst, "wb") as fdst:
                            fdst.write(fsrc.read())
                except Exception:
                    continue

        def _guess_extension(file_name: str, language: str) -> str:
            name = (file_name or "").lower()
            lang = (language or "").lower()
            # Prefer existing extension if present
            if "." in name:
                return name.rsplit(".", 1)[-1]
            if lang in ("python", "py"):
                return "py"
            if lang in ("javascript", "js"):
                return "js"
            if lang in ("typescript", "ts"):
                return "ts"
            if lang in ("bash", "shell", "sh"):
                return "sh"
            if lang in ("yaml", "yml"):
                return "yml"
            if lang in ("json",):
                return "json"
            if "dockerfile" in name:
                return "dockerfile"
            return "txt"

        def _secrets_scan(code: str) -> Dict[str, Any]:
            """Very lightweight secret detection with regex patterns."""
            patterns = {
                "aws_access_key": r"AKIA[0-9A-Z]{16}",
                "aws_secret_key": r"(?i)aws(.{0,20})?(secret|access)[=:].{0,3}([A-Za-z0-9/+=]{40})",
                "github_token": r"ghp_[A-Za-z0-9]{36}",
                "google_api_key": r"AIza[0-9A-Za-z\-_]{35}",
                "private_key": r"-----BEGIN (RSA|EC|DSA|OPENSSH) PRIVATE KEY-----",
            }
            findings = []
            for name, pat in patterns.items():
                try:
                    if re.search(pat, code):
                        findings.append(name)
                except re.error:
                    continue
            return {
                "returncode": 0 if not findings else 1,
                "output": ", ".join(findings) if findings else "no-secrets-found",
            }

        def validate_single_file(user_id: int, file_name: str) -> Dict[str, Any]:
            """×‘×“×™×§×ª ×ª×§×™× ×•×ª ×§×•×‘×¥ ×™×—×™×“"""
            try:
                file_data = db.get_latest_version(user_id, file_name)
                if not file_data:
                    return {'error': '×§×•×‘×¥ ×œ× × ××¦×'}
                
                code = file_data['code']
                language = file_data['programming_language']
                
                # ×‘×“×™×§×ª ×ª×§×™× ×•×ª
                is_valid, cleaned_code, error_msg = code_processor.validate_code_input(code, file_name, user_id)
                result: Dict[str, Any] = {
                    'is_valid': is_valid,
                    'error_message': error_msg,
                    'cleaned_code': cleaned_code,
                    'original_length': len(code) if isinstance(code, str) else 0,
                    'cleaned_length': len(cleaned_code) if isinstance(cleaned_code, str) else 0,
                    'language': language,
                    'advanced_checks': {}
                }

                # ×‘×“×™×§×•×ª ××ª×§×“××•×ª ×œ×¤×™ ×©×¤×”
                with tempfile.TemporaryDirectory(prefix="validate_") as temp_dir:
                    # ×§×‘×¢ ×©× ×§×•×‘×¥ ×–×× ×™ ×œ×¤×™ ×”×©×¤×”/×”×¡×™×•××ª
                    ext = _guess_extension(file_name or "file", language or "")
                    base_name = (file_name or f"file.{ext}").replace("/", "_")
                    if not base_name.lower().endswith(f".{ext}") and ext not in ("dockerfile"):
                        base_name = f"{base_name}.{ext}"
                    temp_file = os.path.join(temp_dir, base_name)
                    os.makedirs(os.path.dirname(temp_file), exist_ok=True)
                    with open(temp_file, 'w', encoding='utf-8') as f:
                        f.write(code)
                    _copy_lint_configs(temp_dir)

                    adv: Dict[str, Any] = {}

                    # Python specific
                    if (language or "").lower() == 'python' or temp_file.endswith('.py'):
                        adv.update(_advanced_python_checks(temp_dir, os.path.basename(temp_file)))
                        # pylint, isort, radon (optional)
                        adv["pylint"] = _run_local_cmd(["pylint", "-sn", os.path.basename(temp_file)], temp_dir)
                        adv["isort"] = _run_local_cmd(["isort", "--check-only", os.path.basename(temp_file)], temp_dir)
                        adv["radon_cc"] = _run_local_cmd(["radon", "cc", "-s", "-a", os.path.basename(temp_file)], temp_dir)
                        adv["radon_mi"] = _run_local_cmd(["radon", "mi", os.path.basename(temp_file)], temp_dir)

                    # JavaScript / TypeScript
                    if temp_file.endswith('.js') or temp_file.endswith('.ts'):
                        adv["eslint"] = _run_local_cmd(["eslint", "-f", "stylish", os.path.basename(temp_file)], temp_dir)
                        if temp_file.endswith('.ts'):
                            adv["tsc"] = _run_local_cmd(["tsc", "--noEmit", os.path.basename(temp_file)], temp_dir)
                        adv["prettier"] = _run_local_cmd(["prettier", "--check", os.path.basename(temp_file)], temp_dir)

                    # Shell scripts
                    if temp_file.endswith('.sh'):
                        adv["shellcheck"] = _run_local_cmd(["shellcheck", os.path.basename(temp_file)], temp_dir)

                    # YAML
                    if temp_file.endswith('.yml') or temp_file.endswith('.yaml'):
                        adv["yamllint"] = _run_local_cmd(["yamllint", os.path.basename(temp_file)], temp_dir)

                    # Dockerfile
                    if ext == 'dockerfile' or os.path.basename(temp_file).lower() == 'dockerfile':
                        adv["hadolint"] = _run_local_cmd(["hadolint", os.path.basename(temp_file)], temp_dir)

                    # JSON
                    if temp_file.endswith('.json'):
                        adv["jq"] = _run_local_cmd(["jq", "-e", ".", os.path.basename(temp_file)], temp_dir)

                    # Semgrep (generic SAST) - optional and quiet
                    adv["semgrep"] = _run_local_cmd(["semgrep", "--quiet", "--config", "auto", os.path.basename(temp_file)], temp_dir)

                    # Internal secrets scan (always available)
                    adv["secrets_scan"] = _secrets_scan(code)

                    result['advanced_checks'] = adv
                # ×¡×™××•×œ×¦×™×™×ª ×–××Ÿ ×¢×™×‘×•×“ ×¨×™××œ×™
                try:
                    delay = min(max(len(code) / 400_000.0, 0.03), 0.2)
                    time.sleep(delay)
                except Exception:
                    pass

                return result
                
            except Exception as e:
                return {'error': str(e)}
        
        # ×”×¨×¦×” ×‘×¨×§×¢ ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×œ×•×œ××” ×”×¨××©×™×ª
        asyncio.create_task(self.process_files_batch(job_id, validate_single_file))
        return job_id
    
    async def export_files_batch(self, user_id: int, file_names: List[str], export_format: str = "zip") -> str:
        """×™×™×¦×•× batch ×©×œ ×§×‘×¦×™×"""
        job_id = self.create_job(user_id, "export", file_names)
        
        def export_single_file(user_id: int, file_name: str, format: str = "zip") -> Dict[str, Any]:
            """×™×™×¦×•× ×§×•×‘×¥ ×™×—×™×“"""
            try:
                file_data = db.get_latest_version(user_id, file_name)
                if not file_data:
                    return {'error': '×§×•×‘×¥ ×œ× × ××¦×'}
                
                # ×”×›× ×ª ×”×§×•×‘×¥ ×œ×™×™×¦×•×
                return {
                    'file_name': file_name,
                    'content': file_data['code'],
                    'language': file_data['programming_language'],
                    'size': len(file_data['code'])
                }
                
            except Exception as e:
                return {'error': str(e)}
        
        # ×”×¨×¦×” ×‘×¨×§×¢ ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×œ×•×œ××” ×”×¨××©×™×ª
        asyncio.create_task(self.process_files_batch(job_id, export_single_file, format=export_format))
        return job_id
    
    def get_job_status(self, job_id: str) -> Optional[BatchJob]:
        """×§×‘×œ×ª ×¡×˜×˜×•×¡ ×¢×‘×•×“×ª batch"""
        return self.active_jobs.get(job_id)
    
    def cleanup_old_jobs(self, max_age_hours: int = 24):
        """× ×™×§×•×™ ×¢×‘×•×“×•×ª ×™×©× ×•×ª"""
        current_time = time.time()
        old_jobs = []
        
        for job_id, job in self.active_jobs.items():
            if job.end_time > 0:  # ×¢×‘×•×“×” ×©×”×¡×ª×™×™××”
                age_hours = (current_time - job.end_time) / 3600
                if age_hours > max_age_hours:
                    old_jobs.append(job_id)
        
        for job_id in old_jobs:
            del self.active_jobs[job_id]
        
        if old_jobs:
            logger.info(f"× ×•×§×• {len(old_jobs)} ×¢×‘×•×“×•×ª batch ×™×©× ×•×ª")
    
    def format_job_summary(self, job: BatchJob) -> str:
        """×¤×•×¨××˜ ×¡×™×›×•× ×¢×‘×•×“×ª batch"""
        try:
            duration = ""
            if job.end_time > 0:
                duration = f" ({job.end_time - job.start_time:.1f}s)"
            
            if job.status == "pending":
                return f"â³ <b>×¢×‘×•×“×” ×××ª×™× ×”</b>\nğŸ“ {job.total} ×§×‘×¦×™× ×œ×¢×™×‘×•×“"
            
            elif job.status == "running":
                progress_percent = (job.progress / job.total * 100) if job.total > 0 else 0
                progress_bar = "â–ˆ" * int(progress_percent / 10) + "â–‘" * (10 - int(progress_percent / 10))
                return (
                    f"âš¡ <b>×¢×‘×•×“×” ×‘×¢×™×‘×•×“...</b>\n"
                    f"ğŸ“Š {job.progress}/{job.total} ({progress_percent:.1f}%)\n"
                    f"[{progress_bar}]"
                )
            
            elif job.status == "completed":
                successful = sum(1 for r in job.results.values() if r.get('success', False))
                failed = job.total - successful
                
                status_emoji = "âœ…" if failed == 0 else "âš ï¸"
                
                return (
                    f"{status_emoji} <b>×¢×‘×•×“×” ×”×•×©×œ××”</b>{duration}\n"
                    f"âœ… ×”×¦×œ×™×—×•: {successful}\n"
                    f"âŒ × ×›×©×œ×•: {failed}\n"
                    f"ğŸ“ ×¡×”\"×›: {job.total} ×§×‘×¦×™×"
                )
            
            elif job.status == "failed":
                return (
                    f"âŒ <b>×¢×‘×•×“×” × ×›×©×œ×”</b>{duration}\n"
                    f"ğŸš¨ ×©×’×™××”: {html_escape(job.error_message)}\n"
                    f"ğŸ“ {job.total} ×§×‘×¦×™×"
                )
            
            return f"â“ ×¡×˜×˜×•×¡ ×œ× ×™×“×•×¢: {job.status}"
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×¤×•×¨××˜ ×¡×™×›×•× job: {e}")
            return "âŒ ×©×’×™××” ×‘×”×¦×’×ª ×¡×™×›×•×"

# ×™×¦×™×¨×ª instance ×’×œ×•×‘×œ×™
batch_processor = BatchProcessor()