# ğŸ“Š ×©×™×¤×•×¨ Logging ×•-Monitoring

## ğŸ” ×××¦××™×

### ××¦×‘ × ×•×›×—×™
- **502 logger calls** ×‘×¨×—×‘×™ ×”×§×•×“ âœ…
- ×¨×•×‘ ×‘×¢×‘×¨×™×ª (×§×©×” ×œ-grep/analytics)
- ××™×Ÿ structured logging
- ××™×Ÿ correlation IDs
- ××™×Ÿ performance metrics
- ××™×Ÿ alerting ×¢×œ ×©×’×™××•×ª ×§×¨×™×˜×™×•×ª

---

## âš ï¸ ×‘×¢×™×•×ª ×¡×¤×¦×™×¤×™×•×ª

### 1. Logging ×‘×¢×‘×¨×™×ª
```python
# ×“×•×’××” ×-database/manager.py:119
logger.info("×”×ª×—×‘×¨×•×ª ×œ××¡×“ ×”× ×ª×•× ×™× ×”×¦×œ×™×—×”...")

# ×‘×¢×™×”:
# - ×§×©×” ×œ×—×¤×©: grep "connection success" ×œ× ×¢×•×‘×“
# - Tools ×›××• Sentry/Datadog ×œ× ××–×”×™× patterns
# - ××™×Ÿ i18n ×××™×ª×™
```

### 2. ×—×¡×¨×™× Correlation IDs
```python
# ×‘×¢×™×”: ××™ ××¤×©×¨ ×œ×¢×§×•×‘ ××—×¨×™ request ××œ×
logger.info("×©×•××¨ ×§×•×‘×¥")  # ××™×–×” ××©×ª××©? ××™×–×” request?
# ... 50 ×©×•×¨×•×ª ××—×¨ ×›×š ...
logger.error("×©×’×™××” ×‘×©××™×¨×”")  # ××•×ª×• request? ××©×ª××© ××—×¨?
```

### 3. ××™×Ÿ Performance Tracking
```python
# ×—×¡×¨:
# - ×›××” ×–××Ÿ ×œ×§×— save?
# - ×›××” ×–××Ÿ ×œ×§×— search?
# - bottlenecks ××™×¤×”?
```

---

## âœ… ×¤×ª×¨×•× ×•×ª ××•××œ×¦×™×

### 1. Structured Logging ×¢× structlog

```python
# utils/logging_config.py
import structlog
import logging

def setup_logging():
    """×”×’×“×¨×ª structured logging"""
    
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.dev.ConsoleRenderer() if DEBUG else structlog.processors.JSONRenderer(),
        ],
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=False,
    )

logger = structlog.get_logger()
```

**×©×™××•×©:**
```python
# âœ… ×˜×•×‘ - structured + ×¢×‘×¨×™×ª ×‘×”×•×“×¢×”
logger.info(
    "file_saved",
    user_id=user_id,
    file_name=file_name,
    size_bytes=len(code),
    language=lang,
    msg_he="×§×•×‘×¥ × ×©××¨ ×‘×”×¦×œ×—×”"
)

# ×‘××§×•×:
# âŒ ×¨×¢
logger.info(f"×§×•×‘×¥ {file_name} × ×©××¨ ×‘×”×¦×œ×—×”")
```

**×™×ª×¨×•× ×•×ª:**
- × ×™×ª×Ÿ ×œ×—×™×¤×•×©: `grep '"event":"file_saved"'`
- × ×™×ª×Ÿ ×œ-parsing ××•×˜×•××˜×™
- ×ª××™×›×” ×‘-analytics tools
- ×¢×‘×¨×™×ª ×‘×©×“×” × ×¤×¨×“

---

### 2. Request Correlation

```python
# middleware/correlation.py
import uuid
from contextvars import ContextVar

request_id_var = ContextVar('request_id', default=None)

def generate_request_id() -> str:
    return str(uuid.uuid4())[:8]  # ×§×¦×¨ ×•× ×•×—

async def correlation_middleware(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """××•×¡×™×£ request_id ×œ×›×œ ×¤×¢×•×œ×”"""
    req_id = generate_request_id()
    request_id_var.set(req_id)
    
    # ×”×•×¡×£ ×œ-context ×œ×’×™×©×” ×‘×›×œ ××§×•×
    context.user_data['request_id'] = req_id
    
    logger.bind(request_id=req_id)  # structlog
    
    return True  # continue to handlers

# ×©×™××•×©:
logger.info("processing_start", request_id=request_id_var.get())
# ... 
logger.info("processing_end", request_id=request_id_var.get())
```

**×ª×•×¦××” ×‘×œ×•×’×™×:**
```json
{"event": "processing_start", "request_id": "a3f2c891", "timestamp": "..."}
{"event": "db_query", "request_id": "a3f2c891", "duration_ms": 45}
{"event": "processing_end", "request_id": "a3f2c891", "total_duration_ms": 120}
```

---

### 3. Performance Tracking

```python
# utils/metrics.py
import time
from contextlib import contextmanager
import structlog

logger = structlog.get_logger()

@contextmanager
def track_performance(operation: str, **extra):
    """Context manager ×œ××“×™×“×ª ×‘×™×¦×•×¢×™×"""
    start = time.time()
    try:
        yield
    finally:
        duration_ms = (time.time() - start) * 1000
        logger.info(
            "performance",
            operation=operation,
            duration_ms=round(duration_ms, 2),
            **extra
        )

# ×©×™××•×©:
async def save_file(user_id: int, file_name: str, code: str):
    with track_performance("save_file", user_id=user_id, file_size=len(code)):
        # ... save logic ...
        pass
```

**×“×•×’××ª ×¤×œ×˜:**
```json
{
  "event": "performance",
  "operation": "save_file",
  "duration_ms": 45.23,
  "user_id": 12345,
  "file_size": 1520
}
```

---

### 4. Error Tracking ×¢× Sentry

```python
# main.py
import sentry_sdk
from sentry_sdk.integrations.logging import LoggingIntegration

sentry_sdk.init(
    dsn=os.getenv("SENTRY_DSN"),
    environment=os.getenv("ENVIRONMENT", "production"),
    traces_sample_rate=0.1,  # 10% ×©×œ transactions
    profiles_sample_rate=0.1,
    integrations=[
        LoggingIntegration(level=logging.INFO, event_level=logging.ERROR)
    ],
    before_send=filter_sensitive_data,  # ×˜×©×˜×•×© × ×ª×•× ×™× ×¨×’×™×©×™×
)

def filter_sensitive_data(event, hint):
    """××¡× ×Ÿ credentials ××œ×•×’×™×"""
    # Remove BOT_TOKEN, passwords, etc.
    if 'extra' in event:
        for key in list(event['extra'].keys()):
            if any(sensitive in key.lower() for sensitive in ['token', 'password', 'secret']):
                event['extra'][key] = '[REDACTED]'
    return event
```

---

### 5. Business Metrics

```python
# utils/business_metrics.py
from dataclasses import dataclass
from datetime import datetime, timezone

@dataclass
class BusinessMetrics:
    """××“×“×™ ×¢×¡×§ ×—×©×•×‘×™×"""
    
    @staticmethod
    async def track_file_saved(user_id: int, language: str, size: int):
        logger.info(
            "business_metric",
            metric="file_saved",
            user_id=user_id,
            language=language,
            size_bytes=size,
            timestamp=datetime.now(timezone.utc).isoformat()
        )
    
    @staticmethod
    async def track_search_performed(user_id: int, query: str, results_count: int):
        logger.info(
            "business_metric",
            metric="search",
            user_id=user_id,
            query_length=len(query),
            results_count=results_count
        )
    
    @staticmethod
    async def track_github_sync(user_id: int, files_count: int, success: bool):
        logger.info(
            "business_metric",
            metric="github_sync",
            user_id=user_id,
            files_count=files_count,
            success=success
        )
```

---

## ğŸ“ˆ Dashboard ×•-Alerts

### Grafana Dashboard (example queries)

```promql
# ×§×¦×‘ ×©××™×¨×•×ª ×œ×“×§×”
rate(file_saved_total[1m])

# ×–××Ÿ ×ª×’×•×‘×” ×××•×¦×¢
histogram_quantile(0.95, rate(operation_duration_seconds_bucket[5m]))

# ×©×™×¢×•×¨ ×©×’×™××•×ª
rate(errors_total[5m]) / rate(requests_total[5m])
```

### Alert Rules

```yaml
# alerts.yml
groups:
  - name: codebot_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(errors_total[5m]) > 0.05
        for: 5m
        annotations:
          summary: "×©×™×¢×•×¨ ×©×’×™××•×ª ×’×‘×•×”: {{ $value }}"
      
      - alert: SlowOperations
        expr: histogram_quantile(0.95, rate(operation_duration_seconds_bucket[5m])) > 2
        for: 10m
        annotations:
          summary: "×¤×¢×•×œ×•×ª ××™×˜×™×•×ª: 95p > 2s"
      
      - alert: MongoDBDown
        expr: up{job="mongodb"} == 0
        for: 1m
        annotations:
          summary: "MongoDB ×œ× ×–××™×Ÿ!"
```

---

## ğŸ”§ ×ª×•×›× ×™×ª ×™×™×©×•×

### ×©×‘×•×¢ 1: Foundation
- [ ] ×”×ª×§× ×ª structlog
- [ ] ×”××¨×ª 50 logger calls ×§×¨×™×˜×™×™×
- [ ] ×”×•×¡×¤×ª request correlation
- [ ] Setup Sentry

### ×©×‘×•×¢ 2: Performance
- [ ] `track_performance` decorator
- [ ] ××“×™×“×ª ×›×œ ×”×¤×¢×•×œ×•×ª ×”×§×¨×™×˜×™×•×ª
- [ ] Dashboard ×¨××©×•×Ÿ

### ×©×‘×•×¢ 3: Business Metrics  
- [ ] track_file_saved
- [ ] track_search
- [ ] track_github_sync
- [ ] weekly reports

### ×©×‘×•×¢ 4: Alerts
- [ ] ×”×’×“×¨×ª alerts
- [ ] Integration ×¢× Telegram/Slack
- [ ] On-call rotation

---

## ğŸ“Š ×“×•×’××ª ×ª×•×¦××”

**×œ×¤× ×™:**
```
2024-01-15 10:23:45 - INFO - ×©×•××¨ ×§×•×‘×¥
2024-01-15 10:23:47 - ERROR - ×©×’×™××” ×‘×©××™×¨×”
```

**××—×¨×™:**
```json
{
  "timestamp": "2024-01-15T10:23:45.123Z",
  "level": "info",
  "event": "file_save_start",
  "request_id": "a3f2c891",
  "user_id": 12345,
  "file_name": "test.py",
  "language": "python",
  "size_bytes": 1520,
  "msg_he": "××ª×—×™×œ ×©××™×¨×ª ×§×•×‘×¥"
}
{
  "timestamp": "2024-01-15T10:23:47.456Z",
  "level": "error",
  "event": "file_save_error",
  "request_id": "a3f2c891",
  "user_id": 12345,
  "error": "DuplicateKeyError",
  "stack_trace": "...",
  "msg_he": "×©×’×™××” ×‘×©××™×¨×ª ×§×•×‘×¥"
}
```

---

## ğŸ¯ ××“×“×™ ×”×¦×œ×—×”

- [ ] ×›×œ request × ×™×ª×Ÿ ×œ××¢×§×‘ end-to-end
- [ ] P95 latency < 500ms
- [ ] Error rate < 1%
- [ ] MTTR (Mean Time To Recovery) < 15 ×“×§×•×ª
- [ ] Dashboard ×‘-Grafana ×¢× 10+ metrics
- [ ] Alerts ×¢×•×‘×“×™× ×‘-production

---

**Bottom line**: Logging ×˜×•×‘ = Debug ××”×™×¨ = ×©×™× ×” ×˜×•×‘×” ğŸ˜´
