# ğŸ—‚ï¸ ×¤×™×¦'×¨: Related Files - ×§×‘×¦×™× ×§×©×•×¨×™×

## ğŸ“‹ ×ª×™××•×¨ ×›×œ×œ×™

××¢×¨×›×ª ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×§×‘×¦×™× ×§×©×•×¨×™× ×¢×œ ×‘×¡×™×¡ ×ª×œ×•×™×•×ª, ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ, ×ª×’×™×•×ª ××©×•×ª×¤×•×ª ×•×–×× ×™ ×¢×¨×™×›×”. ×”×¤×™×¦'×¨ ××¡×¤×§ ×”×§×©×¨ ×˜×•×‘ ×™×•×ª×¨ ×•××¡×™×™×¢ ×‘××¦×™××ª ×§×•×“ ×¨×œ×•×•× ×˜×™.

### ğŸ¯ ××˜×¨×•×ª ×”×¤×™×¦'×¨
- ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×§×‘×¦×™× ×§×©×•×¨×™×
- ×”×§×©×¨ ×˜×•×‘ ×™×•×ª×¨ ×‘×¢×‘×•×“×” ×¢×œ ×”×§×•×“
- ××¦×™××ª ×§×•×“ ×¨×œ×•×•× ×˜×™ ×‘××”×™×¨×•×ª
- ×”×‘× ×ª ××‘× ×” ×”×¤×¨×•×™×§×˜

### ğŸ‘¤ ×ª×¨×—×™×©×™ ×©×™××•×©
1. **Developer ×¢×•×‘×“ ×¢×œ API**: ×¨×•××” ×§×‘×¦×™× ×§×©×•×¨×™× (models, tests, config)
2. **Refactoring**: ××¦×™××ª ×›×œ ×”×§×‘×¦×™× ×©××©×ª××©×™× ×‘×¤×•× ×§×¦×™×”
3. **Learning**: ××¦×™××ª ×“×•×’×××•×ª ×“×•××•×ª ×œ×§×•×“ ×©×›×ª×‘×ª
4. **Debug**: ××¦×™××ª ×§×‘×¦×™× ×©×¢×•×“×›× ×• ×‘××•×ª×• ×–××Ÿ

---

## ğŸ§  ××œ×’×•×¨×™×ª××™ ×–×™×”×•×™

### 1. ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª (Direct Dependencies)
×–×™×”×•×™ imports ×‘×§×•×“:

```python
# api.py
from database import User, Session  # â†’ ×ª×œ×•×ª ×™×©×™×¨×” ×‘-database.py
from config import API_KEY           # â†’ ×ª×œ×•×ª ×™×©×™×¨×” ×‘-config.py
import utils                         # â†’ ×ª×œ×•×ª ×™×©×™×¨×” ×‘-utils.py
```

### 2. ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ (Content Similarity)
×”×©×•×•××ª ×§×•×“ ×¢×œ ×‘×¡×™×¡:
- ×©××•×ª ×¤×•× ×§×¦×™×•×ª/××—×œ×§×•×ª ××©×•×ª×¤×™×
- imports ×“×•××™×
- ××™×œ×•×ª ××¤×ª×— ×—×•×–×¨×•×ª

### 3. ×ª×’×™×•×ª ××©×•×ª×¤×•×ª (Shared Tags)
×§×‘×¦×™× ×¢× ×ª×’×™×•×ª ×“×•××•×ª:
```
api.py: #api #backend #flask
auth.py: #api #backend #auth
models.py: #backend #database
```

### 4. ×–×× ×™ ×¢×¨×™×›×” ×§×¨×•×‘×™× (Temporal Proximity)
×§×‘×¦×™× ×©× ×¢×¨×›×• ×‘××•×ª×• ×¤×¨×§ ×–××Ÿ (24-48 ×©×¢×•×ª)

---

## ğŸ’» ××™××•×© ×§×•×“

### 1. ×× ×•×¢ ×–×™×”×•×™ (related_files_engine.py)

×¦×•×¨ ×§×•×‘×¥ ×—×“×©: `related_files_engine.py`

```python
"""
×× ×•×¢ ×–×™×”×•×™ ×§×‘×¦×™× ×§×©×•×¨×™×
Related Files Detection Engine
"""

import logging
import re
from collections import defaultdict
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Set, Tuple

from fuzzywuzzy import fuzz
from database import db

logger = logging.getLogger(__name__)


class RelatedFilesEngine:
    """×× ×•×¢ ×œ×–×™×”×•×™ ×§×‘×¦×™× ×§×©×•×¨×™×"""
    
    def __init__(self):
        self.import_patterns = {
            'python': [
                r'from\s+(\w+(?:\.\w+)*)\s+import',
                r'import\s+(\w+(?:\.\w+)*)'
            ],
            'javascript': [
                r'import\s+.*\s+from\s+[\'"](.+?)[\'"]',
                r'require\([\'"](.+?)[\'"]\)'
            ],
            'java': [
                r'import\s+([\w.]+);'
            ],
            'go': [
                r'import\s+["\'](.+?)["\']'
            ]
        }
    
    def find_related_files(
        self,
        user_id: int,
        file_name: str,
        max_results: int = 10
    ) -> Dict[str, List[Dict]]:
        """
        ××¦×™××ª ×›×œ ×”×§×‘×¦×™× ×”×§×©×•×¨×™×
        
        Returns:
            ××™×œ×•×Ÿ ×¢× ×§×˜×’×•×¨×™×•×ª: dependencies, similar, same_tags, temporal
        """
        try:
            # ×§×‘×œ×ª ×”×§×•×‘×¥ ×”××§×•×¨×™
            snippet = db.get_code_snippet(user_id, file_name)
            if not snippet:
                logger.warning(f"×§×•×‘×¥ {file_name} ×œ× × ××¦×")
                return {}
            
            results = {
                "dependencies": [],
                "similar": [],
                "same_tags": [],
                "temporal": []
            }
            
            # 1. ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª
            results["dependencies"] = self._find_dependencies(
                user_id, snippet, max_results
            )
            
            # 2. ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ
            results["similar"] = self._find_similar_content(
                user_id, file_name, snippet, max_results
            )
            
            # 3. ×ª×’×™×•×ª ××©×•×ª×¤×•×ª
            results["same_tags"] = self._find_by_tags(
                user_id, file_name, snippet, max_results
            )
            
            # 4. ×–×× ×™ ×¢×¨×™×›×” ×§×¨×•×‘×™×
            results["temporal"] = self._find_by_time(
                user_id, file_name, snippet, max_results
            )
            
            return results
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×¤×•×© ×§×‘×¦×™× ×§×©×•×¨×™×: {e}")
            return {}
    
    def _find_dependencies(
        self,
        user_id: int,
        snippet: Dict,
        max_results: int
    ) -> List[Dict]:
        """×–×™×”×•×™ ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª"""
        try:
            code = snippet.get("code", "")
            language = snippet.get("programming_language", "").lower()
            
            # ×§×‘×œ×ª patterns ×œ×©×¤×”
            patterns = self.import_patterns.get(language, [])
            if not patterns:
                return []
            
            # ×—×™×œ×•×¥ imports
            imported_modules = set()
            for pattern in patterns:
                matches = re.findall(pattern, code, re.MULTILINE)
                imported_modules.update(matches)
            
            if not imported_modules:
                return []
            
            # ×—×™×¤×•×© ×§×‘×¦×™× ×ª×•×××™×
            all_files = db.get_user_files(user_id, limit=1000)
            dependencies = []
            
            for file_data in all_files:
                target_name = file_data["file_name"]
                
                # ×‘×“×™×§×” ×× ×©× ×”×§×•×‘×¥ ×ª×•×× ×œ-import
                for module in imported_modules:
                    # ×”××¨×ª module path ×œ×©× ×§×•×‘×¥
                    possible_names = [
                        f"{module}.py",
                        f"{module.split('.')[-1]}.py",
                        f"{module}.js",
                        f"{module.split('.')[-1]}.js"
                    ]
                    
                    if target_name in possible_names or module in target_name:
                        dependencies.append({
                            "file_name": target_name,
                            "programming_language": file_data.get("programming_language", ""),
                            "import_name": module,
                            "score": 1.0  # ×ª×œ×•×ª ×™×©×™×¨×” = ×¦×™×•×Ÿ ××œ×
                        })
                        break
            
            return dependencies[:max_results]
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×–×™×”×•×™ ×ª×œ×•×™×•×ª: {e}")
            return []
    
    def _find_similar_content(
        self,
        user_id: int,
        file_name: str,
        snippet: Dict,
        max_results: int
    ) -> List[Dict]:
        """××¦×™××ª ×§×‘×¦×™× ×“×•××™× ×‘×ª×•×›×Ÿ"""
        try:
            code = snippet.get("code", "")
            language = snippet.get("programming_language", "")
            
            # ×—×™×œ×•×¥ ×××¤×™×™× ×™×
            source_features = self._extract_features(code)
            
            # ×§×‘×œ×ª ×§×‘×¦×™× ×‘××•×ª×” ×©×¤×”
            all_files = db.get_user_files(user_id, limit=1000)
            similar_files = []
            
            for file_data in all_files:
                target_name = file_data["file_name"]
                if target_name == file_name:
                    continue
                
                # ×¨×§ ×§×‘×¦×™× ×‘××•×ª×” ×©×¤×”
                if file_data.get("programming_language") != language:
                    continue
                
                target_code = file_data.get("code", "")
                target_features = self._extract_features(target_code)
                
                # ×—×™×©×•×‘ ×“××™×•×Ÿ
                similarity = self._calculate_similarity(
                    source_features, target_features
                )
                
                if similarity > 0.3:  # ×¡×£ ××™× ×™××œ×™
                    similar_files.append({
                        "file_name": target_name,
                        "programming_language": language,
                        "similarity": similarity,
                        "score": similarity
                    })
            
            # ××™×•×Ÿ ×œ×¤×™ ×“××™×•×Ÿ
            similar_files.sort(key=lambda x: x["score"], reverse=True)
            
            return similar_files[:max_results]
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×¤×•×© ×“××™×•×Ÿ: {e}")
            return []
    
    def _extract_features(self, code: str) -> Dict[str, Set[str]]:
        """×—×™×œ×•×¥ ×××¤×™×™× ×™× ××§×•×“"""
        features = {
            "functions": set(),
            "classes": set(),
            "imports": set(),
            "keywords": set()
        }
        
        try:
            # ×¤×•× ×§×¦×™×•×ª (Python, JS)
            func_pattern = r'(?:def|function|async\s+function)\s+(\w+)'
            features["functions"] = set(re.findall(func_pattern, code))
            
            # ××—×œ×§×•×ª
            class_pattern = r'class\s+(\w+)'
            features["classes"] = set(re.findall(class_pattern, code))
            
            # imports
            import_pattern = r'(?:import|from|require)\s+(\w+)'
            features["imports"] = set(re.findall(import_pattern, code))
            
            # ××™×œ×•×ª ××¤×ª×— × ×¤×•×¦×•×ª
            words = re.findall(r'\b\w{4,}\b', code.lower())
            features["keywords"] = set([w for w in words if len(w) >= 4])
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×œ×•×¥ ×××¤×™×™× ×™×: {e}")
        
        return features
    
    def _calculate_similarity(
        self,
        features1: Dict[str, Set[str]],
        features2: Dict[str, Set[str]]
    ) -> float:
        """×—×™×©×•×‘ ×“××™×•×Ÿ ×‘×™×Ÿ ×©× ×™ ×§×‘×¦×™×"""
        try:
            scores = []
            
            # ×“××™×•×Ÿ ×‘×¤×•× ×§×¦×™×•×ª (××©×§×œ ×’×‘×•×”)
            if features1["functions"] and features2["functions"]:
                common = features1["functions"] & features2["functions"]
                total = features1["functions"] | features2["functions"]
                func_score = len(common) / len(total) if total else 0
                scores.append(func_score * 2)  # ××©×§×œ ×›×¤×•×œ
            
            # ×“××™×•×Ÿ ×‘××—×œ×§×•×ª
            if features1["classes"] and features2["classes"]:
                common = features1["classes"] & features2["classes"]
                total = features1["classes"] | features2["classes"]
                class_score = len(common) / len(total) if total else 0
                scores.append(class_score * 1.5)
            
            # ×“××™×•×Ÿ ×‘-imports
            if features1["imports"] and features2["imports"]:
                common = features1["imports"] & features2["imports"]
                total = features1["imports"] | features2["imports"]
                import_score = len(common) / len(total) if total else 0
                scores.append(import_score * 1.2)
            
            # ×“××™×•×Ÿ ×‘××™×œ×•×ª ××¤×ª×—
            if features1["keywords"] and features2["keywords"]:
                # ×¨×§ 50 ××™×œ×•×ª ×”××¤×ª×— ×”× ×¤×•×¦×•×ª
                kw1 = set(list(features1["keywords"])[:50])
                kw2 = set(list(features2["keywords"])[:50])
                common = kw1 & kw2
                total = kw1 | kw2
                kw_score = len(common) / len(total) if total else 0
                scores.append(kw_score)
            
            # ×××•×¦×¢ ××©×•×§×œ×œ
            return sum(scores) / len(scores) if scores else 0
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×©×•×‘ ×“××™×•×Ÿ: {e}")
            return 0
    
    def _find_by_tags(
        self,
        user_id: int,
        file_name: str,
        snippet: Dict,
        max_results: int
    ) -> List[Dict]:
        """××¦×™××ª ×§×‘×¦×™× ×¢× ×ª×’×™×•×ª ××©×•×ª×¤×•×ª"""
        try:
            tags = snippet.get("tags", [])
            if not tags:
                return []
            
            # ×—×™×¤×•×© ×§×‘×¦×™× ×¢× ×ª×’×™×•×ª ×—×•×¤×¤×•×ª
            all_files = db.get_user_files(user_id, limit=1000)
            tagged_files = []
            
            source_tags = set(tags)
            
            for file_data in all_files:
                target_name = file_data["file_name"]
                if target_name == file_name:
                    continue
                
                target_tags = set(file_data.get("tags", []))
                if not target_tags:
                    continue
                
                # ×—×™×©×•×‘ ×—×¤×™×¤×”
                common = source_tags & target_tags
                if not common:
                    continue
                
                overlap = len(common) / len(source_tags | target_tags)
                
                tagged_files.append({
                    "file_name": target_name,
                    "programming_language": file_data.get("programming_language", ""),
                    "common_tags": list(common),
                    "overlap": overlap,
                    "score": overlap
                })
            
            tagged_files.sort(key=lambda x: x["score"], reverse=True)
            return tagged_files[:max_results]
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×¤×•×© ×œ×¤×™ ×ª×’×™×•×ª: {e}")
            return []
    
    def _find_by_time(
        self,
        user_id: int,
        file_name: str,
        snippet: Dict,
        max_results: int
    ) -> List[Dict]:
        """××¦×™××ª ×§×‘×¦×™× ×©× ×¢×¨×›×• ×‘×–××Ÿ ×“×•××”"""
        try:
            updated_at = snippet.get("updated_at")
            if not updated_at:
                return []
            
            # ×—×œ×•×Ÿ ×–××Ÿ ×©×œ 48 ×©×¢×•×ª
            time_window = timedelta(hours=48)
            start_time = updated_at - time_window
            end_time = updated_at + time_window
            
            # ×—×™×¤×•×© ×§×‘×¦×™× ×‘×—×œ×•×Ÿ ×–××Ÿ
            all_files = db.get_user_files(user_id, limit=1000)
            temporal_files = []
            
            for file_data in all_files:
                target_name = file_data["file_name"]
                if target_name == file_name:
                    continue
                
                target_time = file_data.get("updated_at")
                if not target_time:
                    continue
                
                # ×‘×“×™×§×” ×× ×‘×—×œ×•×Ÿ ×–××Ÿ
                if start_time <= target_time <= end_time:
                    # ×—×™×©×•×‘ ×§×¨×‘×” ×‘×–××Ÿ
                    time_diff = abs((target_time - updated_at).total_seconds())
                    hours_diff = time_diff / 3600
                    proximity = max(0, 1 - (hours_diff / 48))  # ×¦×™×•×Ÿ ×œ×¤×™ ×§×¨×‘×”
                    
                    temporal_files.append({
                        "file_name": target_name,
                        "programming_language": file_data.get("programming_language", ""),
                        "updated_at": target_time,
                        "hours_diff": hours_diff,
                        "score": proximity
                    })
            
            temporal_files.sort(key=lambda x: x["score"], reverse=True)
            return temporal_files[:max_results]
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×—×™×¤×•×© ×œ×¤×™ ×–××Ÿ: {e}")
            return []


# ×™×¦×™×¨×ª instance ×’×œ×•×‘×œ×™
related_engine = RelatedFilesEngine()
```

---

### 2. Handler (related_files_handler.py)

```python
"""
××˜×¤×œ ×‘×§×‘×¦×™× ×§×©×•×¨×™× - Related Files Handler
"""

import logging
from typing import Dict, List

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode
from telegram.ext import CommandHandler, CallbackQueryHandler, ContextTypes

from database import db
from utils import get_language_emoji
from related_files_engine import related_engine
from activity_reporter import create_reporter

logger = logging.getLogger(__name__)

reporter = create_reporter(
    mongodb_uri="mongodb+srv://mumin:M43M2TFgLfGvhBwY@muminai.tm6x81b.mongodb.net/?retryWrites=true&w=majority&appName=muminAI",
    service_id="srv-d3ilh4vfte5s7392s000",
    service_name="CodeBot3"
)


async def related_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    ×¤×§×•×“×”: /related <file_name>
    ×”×¦×’×ª ×§×‘×¦×™× ×§×©×•×¨×™×
    """
    reporter.report_activity(update.effective_user.id)
    user_id = update.effective_user.id
    
    if not context.args:
        await update.message.reply_text(
            "ğŸ—‚ï¸ <b>×§×‘×¦×™× ×§×©×•×¨×™×</b>\n\n"
            "×©×™××•×©: <code>/related &lt;file_name&gt;</code>\n\n"
            "×“×•×’××”:\n"
            "<code>/related api.py</code>\n\n"
            "×”×‘×•×˜ ×™××¦× ×§×‘×¦×™× ×§×©×•×¨×™× ×¢×œ ×‘×¡×™×¡:\n"
            "â€¢ ×ª×œ×•×™×•×ª (imports)\n"
            "â€¢ ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ\n"
            "â€¢ ×ª×’×™×•×ª ××©×•×ª×¤×•×ª\n"
            "â€¢ ×–×× ×™ ×¢×¨×™×›×” ×§×¨×•×‘×™×",
            parse_mode=ParseMode.HTML
        )
        return
    
    file_name = " ".join(context.args)
    
    # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×§×™×™×
    snippet = db.get_code_snippet(user_id, file_name)
    if not snippet:
        await update.message.reply_text(
            f"âŒ ×”×§×•×‘×¥ <code>{file_name}</code> ×œ× × ××¦×.",
            parse_mode=ParseMode.HTML
        )
        return
    
    # ×”×•×“×¢×ª ×”××ª× ×”
    wait_msg = await update.message.reply_text(
        "ğŸ” ××—×¤×© ×§×‘×¦×™× ×§×©×•×¨×™×..."
    )
    
    # ×—×™×¤×•×©
    related = related_engine.find_related_files(user_id, file_name, max_results=8)
    
    # ×‘× ×™×™×ª ×”×•×“×¢×”
    message_lines = [
        f"ğŸ—‚ï¸ <b>×§×‘×¦×™× ×§×©×•×¨×™× ×œ-{file_name}</b>\n"
    ]
    
    has_results = False
    
    # ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª
    if related.get("dependencies"):
        has_results = True
        message_lines.append("ğŸ“Œ <b>×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª:</b>")
        for dep in related["dependencies"][:5]:
            name = dep["file_name"]
            import_name = dep.get("import_name", "")
            emoji = get_language_emoji(dep.get("programming_language", ""))
            message_lines.append(
                f"   {emoji} <code>{name}</code>\n"
                f"      â””â”€ import: <code>{import_name}</code>"
            )
        message_lines.append("")
    
    # ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ
    if related.get("similar"):
        has_results = True
        message_lines.append("ğŸ¯ <b>×“×•××™× ×‘×ª×•×›×Ÿ:</b>")
        for sim in related["similar"][:5]:
            name = sim["file_name"]
            score = sim.get("similarity", 0)
            emoji = get_language_emoji(sim.get("programming_language", ""))
            percentage = int(score * 100)
            message_lines.append(
                f"   {emoji} <code>{name}</code> ({percentage}% ×“××™×•×Ÿ)"
            )
        message_lines.append("")
    
    # ×ª×’×™×•×ª ××©×•×ª×¤×•×ª
    if related.get("same_tags"):
        has_results = True
        message_lines.append("ğŸ·ï¸ <b>×ª×’×™×•×ª ××©×•×ª×¤×•×ª:</b>")
        for tagged in related["same_tags"][:5]:
            name = tagged["file_name"]
            common = tagged.get("common_tags", [])
            emoji = get_language_emoji(tagged.get("programming_language", ""))
            tags_str = " ".join([f"#{t}" for t in common[:3]])
            message_lines.append(
                f"   {emoji} <code>{name}</code>\n"
                f"      â””â”€ {tags_str}"
            )
        message_lines.append("")
    
    # ×–×× ×™ ×¢×¨×™×›×”
    if related.get("temporal"):
        has_results = True
        message_lines.append("â±ï¸ <b>× ×¢×¨×›×• ×‘××•×ª×• ×–××Ÿ:</b>")
        for temp in related["temporal"][:5]:
            name = temp["file_name"]
            hours = temp.get("hours_diff", 0)
            emoji = get_language_emoji(temp.get("programming_language", ""))
            time_str = f"{int(hours)} ×©×¢×•×ª" if hours >= 1 else "×¤×—×•×ª ××©×¢×”"
            message_lines.append(
                f"   {emoji} <code>{name}</code> (×”×¤×¨×©: {time_str})"
            )
        message_lines.append("")
    
    if not has_results:
        message_lines.append("ğŸ’­ ×œ× × ××¦××• ×§×‘×¦×™× ×§×©×•×¨×™×.")
    
    message = "\n".join(message_lines)
    
    # ×›×¤×ª×•×¨×™×
    keyboard = []
    
    # ×›×¤×ª×•×¨×™× ×œ×§×‘×¦×™× ×”×§×©×•×¨×™× ×”×¨××©×•× ×™×
    all_related = []
    for category in ["dependencies", "similar", "same_tags", "temporal"]:
        all_related.extend(related.get(category, []))
    
    # ×”×¡×¨×ª ×›×¤×™×œ×•×™×•×ª
    seen = set()
    unique_related = []
    for item in all_related:
        name = item["file_name"]
        if name not in seen:
            seen.add(name)
            unique_related.append(item)
    
    # ×›×¤×ª×•×¨×™× (×¢×“ 6)
    file_buttons = []
    for item in unique_related[:6]:
        name = item["file_name"]
        file_buttons.append(
            InlineKeyboardButton(
                f"ğŸ“„ {name[:18]}",
                callback_data=f"show_{name}"
            )
        )
    
    for i in range(0, len(file_buttons), 2):
        keyboard.append(file_buttons[i:i+2])
    
    # ×›×¤×ª×•×¨ ×¨×¢× ×•×Ÿ
    keyboard.append([
        InlineKeyboardButton("ğŸ”„ ×¨×¢× ×Ÿ ×—×™×¤×•×©", callback_data=f"related_refresh_{file_name}")
    ])
    
    await wait_msg.edit_text(
        message,
        parse_mode=ParseMode.HTML,
        reply_markup=InlineKeyboardMarkup(keyboard) if keyboard else None
    )


async def related_callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """××˜×¤×œ ×‘×œ×—×™×¦×•×ª"""
    query = update.callback_query
    await query.answer()
    
    data = query.data
    
    if data.startswith("related_refresh_"):
        file_name = data.replace("related_refresh_", "")
        user_id = update.effective_user.id
        
        await query.edit_message_text("ğŸ” ××¨×¢× ×Ÿ...")
        
        related = related_engine.find_related_files(user_id, file_name, max_results=8)
        
        # ×‘× ×™×™×ª ×”×•×“×¢×” ××—×“×© (×›××• ×‘-related_command)
        # ...


def setup_related_files_handlers(application):
    """×¨×™×©×•× handlers"""
    application.add_handler(CommandHandler("related", related_command))
    application.add_handler(CallbackQueryHandler(
        related_callback_handler,
        pattern="^related_refresh_"
    ))
```

---

### 3. ×©×™×œ×•×‘ ×‘-main.py

```python
from related_files_handler import setup_related_files_handlers

setup_related_files_handlers(application)
```

---

### 4. ×©×™×œ×•×‘ ×‘×”×¦×’×ª ×§×•×‘×¥

```python
# ×‘-show_command ×‘-bot_handlers.py:

keyboard = [
    # ... ×›×¤×ª×•×¨×™× ×§×™×™××™×
    [
        InlineKeyboardButton("ğŸ—‚ï¸ ×§×‘×¦×™× ×§×©×•×¨×™×", callback_data=f"related_{file_name}"),
        InlineKeyboardButton("ğŸ“Š × ×™×ª×•×—", callback_data=f"analyze_{file_name}")
    ],
    # ...
]
```

---

## ğŸ¨ ×¢×™×¦×•×‘ UI/UX

```
ğŸ—‚ï¸ ×§×‘×¦×™× ×§×©×•×¨×™× ×œ-api.py

ğŸ“Œ ×ª×œ×•×™×•×ª ×™×©×™×¨×•×ª:
   ğŸ database.py
      â””â”€ import: database
   ğŸ config.py
      â””â”€ import: config

ğŸ¯ ×“×•××™× ×‘×ª×•×›×Ÿ:
   ğŸ auth_api.py (75% ×“××™×•×Ÿ)
   ğŸ user_api.py (68% ×“××™×•×Ÿ)

ğŸ·ï¸ ×ª×’×™×•×ª ××©×•×ª×¤×•×ª:
   ğŸ models.py
      â””â”€ #api #backend
   ğŸ tests.py
      â””â”€ #api #tests

â±ï¸ × ×¢×¨×›×• ×‘××•×ª×• ×–××Ÿ:
   ğŸ requirements.txt (2 ×©×¢×•×ª)
   ğŸ README.md (3 ×©×¢×•×ª)

[ğŸ“„ database.py] [ğŸ“„ auth_api.py]
[ğŸ“„ models.py] [ğŸ“„ tests.py]
[ğŸ”„ ×¨×¢× ×Ÿ ×—×™×¤×•×©]
```

---

## âœ… ×¨×©×™××ª ××©×™××•×ª

- [ ] ×× ×•×¢ ×–×™×”×•×™ ×ª×œ×•×™×•×ª
- [ ] ×× ×•×¢ ×“××™×•×Ÿ ×‘×ª×•×›×Ÿ
- [ ] ×–×™×”×•×™ ×œ×¤×™ ×ª×’×™×•×ª
- [ [ ×–×™×”×•×™ ×œ×¤×™ ×–××Ÿ
- [ ] Handler ×œ×ª×¦×•×’×”
- [ ] ××•×¤×˜×™××™×–×¦×™×” (caching)
- [ ] ×ª××™×›×” ×‘×©×¤×•×ª × ×•×¡×¤×•×ª
- [ ] ×©×™×œ×•×‘ ×‘UI

---

**×¡×™×•× ××“×¨×™×š Related Files** ğŸ—‚ï¸
