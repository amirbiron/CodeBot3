#!/usr/bin/env python3
"""
×‘×•×˜ ×©×•××¨ ×§×‘×¦×™ ×§×•×“ - Code Keeper Bot
× ×§×•×“×ª ×”×›× ×™×¡×” ×”×¨××©×™×ª ×œ×‘×•×˜
"""

from __future__ import annotations

# ×”×’×“×¨×•×ª ××ª×§×“××•×ª
import os
import logging
import asyncio
from datetime import datetime
from io import BytesIO

import signal
import sys
import time
try:
    import pymongo  # type: ignore
    _HAS_PYMONGO = True
except Exception:
    pymongo = None  # type: ignore
    _HAS_PYMONGO = False
from datetime import datetime, timezone, timedelta
import atexit
try:
    import pymongo.errors  # type: ignore
    from pymongo.errors import DuplicateKeyError  # type: ignore
except Exception:
    class _DummyErr(Exception):
        pass
    class _DummyErrors:
        InvalidOperation = _DummyErr
        OperationFailure = _DummyErr
    DuplicateKeyError = _DummyErr  # type: ignore
    pymongo = type("_PM", (), {"errors": _DummyErrors})()  # type: ignore
import os

from telegram import Update, ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, BotCommandScopeChat
from telegram.constants import ParseMode
from telegram.ext import (Application, CommandHandler, ContextTypes,
                          MessageHandler, filters, Defaults, ConversationHandler, CallbackQueryHandler,
                          PicklePersistence, InlineQueryHandler, ApplicationHandlerStop)

from config import config
from database import CodeSnippet, DatabaseManager, db
from services import code_service as code_processor
from bot_handlers import AdvancedBotHandlers  # still used by legacy code
from conversation_handlers import MAIN_KEYBOARD, get_save_conversation_handler
from activity_reporter import create_reporter
from github_menu_handler import GitHubMenuHandler
from backup_menu_handler import BackupMenuHandler
from handlers.drive.menu import GoogleDriveMenuHandler
from file_manager import backup_manager
from large_files_handler import large_files_handler
from user_stats import user_stats
from cache_commands import setup_cache_handlers  # enabled
# from enhanced_commands import setup_enhanced_handlers  # disabled
from batch_commands import setup_batch_handlers
from html import escape as html_escape
try:
    from aiohttp import web  # for internal web server
except Exception:
    class _DummyWeb:
        class Application:
            def __init__(self, *a, **k): pass
        class AppRunner:
            def __init__(self, *a, **k): pass
            async def setup(self): pass
        class TCPSite:
            def __init__(self, *a, **k): pass
            async def start(self): pass
        async def json_response(*a, **k):
            return None
    web = _DummyWeb()

# (Lock mechanism constants removed)

# ×”×’×“×¨×ª ×œ×•×’×¨ ××ª×§×“×
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
# ×”×ª×§× ×ª ××¡× ×Ÿ ×˜×©×˜×•×© × ×ª×•× ×™× ×¨×’×™×©×™×
try:
    from utils import install_sensitive_filter
    install_sensitive_filter()
except Exception:
    pass

logger = logging.getLogger(__name__)

# ×”×•×“×¢×ª ×”×ª×—×œ×” ××¨×©×™××”
logger.info("ğŸš€ ××¤×¢×™×œ ×‘×•×˜ ×§×•×“ ××ª×§×“× - ×’×¨×¡×” ×¤×¨×•!")

# ×”×¤×—×ª×ª ×¨×¢×© ×‘×œ×•×’×™×
logging.getLogger("httpx").setLevel(logging.ERROR)  # ×¨×§ ×©×’×™××•×ª ×§×¨×™×˜×™×•×ª
logging.getLogger("telegram.ext.Updater").setLevel(logging.ERROR)
logging.getLogger("telegram.ext.Application").setLevel(logging.WARNING)

# ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ reporter ×’×œ×•×‘×œ×™
reporter = create_reporter(
    mongodb_uri=(os.getenv('REPORTER_MONGODB_URL') or os.getenv('REPORTER_MONGODB_URI') or config.MONGODB_URL),
    service_id=os.getenv('REPORTER_SERVICE_ID', 'srv-d29d72adbo4c73bcuep0'),
    service_name="CodeBot"
)

# ===== ×¢×–×¨: ×©×œ×™×—×ª ×”×•×“×¢×ª ××“××™×Ÿ =====
def get_admin_ids() -> list[int]:
    try:
        raw = os.getenv('ADMIN_USER_IDS')
        if not raw:
            return []
        return [int(x.strip()) for x in raw.split(',') if x.strip().isdigit()]
    except Exception:
        return []

async def notify_admins(context: ContextTypes.DEFAULT_TYPE, text: str) -> None:
    try:
        admin_ids = get_admin_ids()
        if not admin_ids:
            return
        for admin_id in admin_ids:
            try:
                await context.bot.send_message(chat_id=admin_id, text=text)
            except Exception:
                pass
    except Exception:
        pass

# ===== Admin: /recycle_backfill =====
async def recycle_backfill_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """×××œ× deleted_at ×•-deleted_expires_at ×œ×¨×©×•××•×ª ××—×•×§×•×ª ×¨×›×•×ª ×•×—×•×©×‘ TTL.

    ×©×™××•×©: /recycle_backfill [X]
    X = ×™××™× ×œ×ª×•×§×£ ×¡×œ (×‘×¨×™×¨×ª ××—×“×œ ××”×§×•× ×¤×™×’ RECYCLE_TTL_DAYS)
    ×”×¤×§×•×“×” ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“.
    """
    try:
        user_id = update.effective_user.id if update and update.effective_user else 0
        admin_ids = get_admin_ids()
        if not admin_ids or user_id not in admin_ids:
            try:
                await update.message.reply_text("âŒ ×¤×§×•×“×” ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“")
            except Exception:
                pass
            return

        # ×§×‘×™×¢×ª TTL ×‘×™××™×
        try:
            ttl_days = int(context.args[0]) if context.args else int(getattr(config, 'RECYCLE_TTL_DAYS', 7) or 7)
        except Exception:
            ttl_days = int(getattr(config, 'RECYCLE_TTL_DAYS', 7) or 7)
        ttl_days = max(1, ttl_days)

        now = datetime.now(timezone.utc)
        expires = now + timedelta(days=ttl_days)

        # ×•×“× ××™× ×“×§×¡×™ TTL ×•××—"×› Backfill ×‘×©×ª×™ ×”×§×•×œ×§×¦×™×•×ª
        from database import db as _db
        results = []
        for coll_name, friendly in (("collection", "×§×‘×¦×™× ×¨×’×™×œ×™×"), ("large_files_collection", "×§×‘×¦×™× ×’×“×•×œ×™×")):
            coll = getattr(_db, coll_name, None)
            # ×—×©×•×‘: ××œ ×ª×©×ª××©×• ×‘-truthiness ×¢×œ ×§×•×œ×§×¦×™×” ×©×œ PyMongo
            if coll is None:
                results.append((friendly, 0, 0, "collection-missing"))
                continue
            # ensure TTL index idempotently
            try:
                coll.create_index("deleted_expires_at", expireAfterSeconds=0, name="deleted_ttl")
            except Exception:
                # ×œ× ×§×¨×™×˜×™; × ××©×™×š
                pass

            modified_deleted_at = 0
            modified_deleted_exp = 0
            # backfill deleted_at where missing
            try:
                if hasattr(coll, 'update_many'):
                    r1 = coll.update_many({"is_active": False, "deleted_at": {"$exists": False}}, {"$set": {"deleted_at": now}})
                    modified_deleted_at = int(getattr(r1, 'modified_count', 0) or 0)
            except Exception:
                pass
            # backfill deleted_expires_at where missing
            try:
                if hasattr(coll, 'update_many'):
                    r2 = coll.update_many({"is_active": False, "deleted_expires_at": {"$exists": False}}, {"$set": {"deleted_expires_at": expires}})
                    modified_deleted_exp = int(getattr(r2, 'modified_count', 0) or 0)
            except Exception:
                pass

            results.append((friendly, modified_deleted_at, modified_deleted_exp, None))

        # ×“×•"×—
        lines = [
            f"ğŸ§¹ Backfill ×¡×œ ××™×—×–×•×¨ (TTL={ttl_days} ×™××™×)",
        ]
        for friendly, c_at, c_exp, err in results:
            if err:
                lines.append(f"â€¢ {friendly}: ×“×™×œ×•×’ ({err})")
            else:
                lines.append(f"â€¢ {friendly}: deleted_at={c_at}, deleted_expires_at={c_exp}")
        try:
            await update.message.reply_text("\n".join(lines))
        except Exception:
            pass
    except Exception as e:
        try:
            await update.message.reply_text(f"âŒ ×©×’×™××” ×‘-backfill: {html_escape(str(e))}")
        except Exception:
            pass

async def log_user_activity(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    ×¨×™×©×•× ×¤×¢×™×œ×•×ª ××©×ª××© ×‘××¢×¨×›×ª.
    
    Args:
        update: ××•×‘×™×™×§×˜ Update ××˜×œ×’×¨×
        context: ×”×§×•× ×˜×§×¡×˜ ×©×œ ×”×©×™×—×”
    
    Note:
        ×¤×•× ×§×¦×™×” ×–×• × ×§×¨××ª ××•×˜×•××˜×™×ª ×¢×‘×•×¨ ×›×œ ×¤×¢×•×œ×” ×©×œ ××©×ª××©
    """
    if not update.effective_user:
        return

    # ×“×’×™××” ×œ×”×¤×—×ª×ª ×¢×•××¡: ×¨×§ ~25% ××”××™×¨×•×¢×™× ×™×¢×“×›× ×• ××™×™×“×™×ª ××ª ×”-DB
    try:
        import random as _rnd
        sampled = (_rnd.random() < 0.25)
    except Exception:
        sampled = True

    # ×¨×™×©×•× ×‘×¡×™×¡×™ ×œ×’××¨×™ ××—×•×¥ ×œ-try ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×¤×œ×•××•
    try:
        # ×›×“×™ ×œ×©××¨ ×¡×¤×™ milestones, ×× ×“×•×’××™× â€” × ×›×¤×™×œ ××ª ×”××©×§×œ ×‘×”×ª×× ×œ×”×¡×ª×‘×¨×•×ª ×”×“×’×™××”
        if sampled:
            # p=0.25 -> weight=4; ×× ××©×ª× ×” â€” × ×©××‘ ××”×§×•× ×¤×™×’ ×‘×¢×ª×™×“
            weight = 4
            try:
                user_stats.log_user(update.effective_user.id, update.effective_user.username, weight=weight)
            except TypeError:
                # ×ª××™××•×ª ×œ××—×•×¨ ×œ×˜×¡×˜×™×/×¡×‘×™×‘×” ×™×©× ×” ×œ×œ× ×¤×¨××˜×¨ weight
                user_stats.log_user(update.effective_user.id, update.effective_user.username)
    except Exception:
        pass

    # milestones â€” ×œ×”×¨×¦×” ××¡×™× ×›×¨×•× ×™×ª ×›×š ×©×œ× ×ª×—×¡×•× ××ª ×”×”×•×“×¢×” ×œ××©×ª××©
    async def _milestones_job(user_id: int, username: str | None):
        try:
            # ×˜×¢×™× ×” ×“×™× ××™×ª ×©×œ ××•×“×•×œ ×”-DB ×›×“×™ ×œ×¢×‘×•×“ ×”×™×˜×‘ ×¢× monkeypatch ×‘×˜×¡×˜×™×
            from database import db as _db
            users_collection = _db.db.users if getattr(_db, 'db', None) else None
            if users_collection is None:
                return
            doc = users_collection.find_one({"user_id": user_id}, {"total_actions": 1, "milestones_sent": 1}) or {}
            total_actions = int(doc.get("total_actions") or 0)
            already_sent = set(doc.get("milestones_sent") or [])
            milestones = [50, 100, 200, 500, 1000]
            pending = [m for m in milestones if m <= total_actions and m not in already_sent]
            if not pending:
                return
            milestone = max(pending)
            # ×”×ª×¨××ª ××“××™×Ÿ ××•×§×“××ª (×œ×¦×•×¨×š × ×™×˜×•×¨), ×‘× ×•×¡×£ ×œ×”×ª×¨××” ××—×¨×™ ×¢×“×›×•×Ÿ DB
            if milestone >= 500:
                uname = (username or f"User_{user_id}")
                display = f"@{uname}" if uname and not str(uname).startswith('@') else str(uname)
                # ×§×¨×™××” ×™×©×™×¨×” ×œ×œ× ×¢×˜×™×¤×ª try ×›×“×™ ×©×œ× × ×‘×œ×¢ ×‘×©×•×’×’; ×”-wrapper ×”×—×™×¦×•× ×™ ×™×ª×¤×•×¡ ×—×¨×™×’×•×ª
                await notify_admins(context, f"ğŸ“¢ ××©×ª××© {display} ×”×’×™×¢ ×œÖ¾{milestone} ×¤×¢×•×œ×•×ª ×‘×‘×•×˜")
            res = users_collection.update_one(
                {"user_id": user_id, "milestones_sent": {"$ne": milestone}},
                {"$addToSet": {"milestones_sent": milestone}, "$set": {"updated_at": datetime.now(timezone.utc)}}
            )
            if getattr(res, 'modified_count', 0) > 0:
                messages = {
                    50: (
                        "×•×•××•! ××ª×” ×‘×™×Ÿ ×”××©×ª××©×™× ×”××•×‘×™×œ×™× ×‘×‘×•×˜ ğŸ”¥\n"
                        "×”× ×•×›×—×•×ª ×©×œ×š ×¢×•×©×” ×œ× ×• ×©××— ğŸ˜Š\n"
                        "×™×© ×œ×š ×¨×¢×™×•× ×•×ª ××• ×“×‘×¨×™× ×©×”×™×™×ª ×¨×•×¦×” ×œ×¨××•×ª ×›××Ÿ?\n"
                        "××•×–××Ÿ ×œ×›×ª×•×‘ ×œÖ¾@moominAmir"
                    ),
                    100: (
                        "ğŸ’¯ ×¤×¢×•×œ×•×ª!\n"
                        "×›× ×¨××” ×©××ª×” ×›×‘×¨ ×™×•×“×¢ ××ª ×”×‘×•×˜ ×™×•×ª×¨ ×˜×•×‘ ××× ×™ ğŸ˜‚\n"
                        "×™××œ×œ×”, ××•×œ×™ × ×¢×©×” ×œ×š ×ª×¢×•×“×ª ××©×ª××© ×•×ª×™×§? ğŸ†"
                    ),
                    200: (
                        "×•×•××•! 200 ×¤×¢×•×œ×•×ª! ğŸš€\n"
                        "××ª×” ×œ×’××¨×™ ×‘×™×Ÿ ×”××©×ª××©×™× ×”×›×™ ×¤×¢×™×œ×™×.\n"
                        "×™×© ×¤×™×¦'×¨ ×©×”×™×™×ª ×¨×•×¦×” ×œ×¨××•×ª ×‘×”××©×š?\n"
                        "×¡×¤×¨ ×œ× ×• ×‘Ö¾@moominAmir"
                    ),
                    500: (
                        "500 ×¤×¢×•×œ×•×ª! ğŸ”¥\n"
                        "××’×™×¢ ×œ×š ×ª×•×“×” ×¢× ×§×™×ª ×¢×œ ×”×ª××™×›×”! ğŸ©µ"
                    ),
                    1000: (
                        "×”×’×¢×ª ×œÖ¾1000 ×¤×¢×•×œ×•×ª! ğŸ‰\n"
                        "××ª×” ××’×“×” ×—×™×” ×©×œ ×”×‘×•×˜ ×”×–×” ğŸ™Œ\n"
                        "×ª×•×“×” ×©××ª×” ××™×ª× ×• ×œ××•×¨×š ×”×“×¨×š ğŸ’™\n"
                        "×”×¦×¢×•×ª ×œ×©×™×¤×•×¨ ×™×ª×§×‘×œ×• ×‘×‘×¨×›×” â£ï¸\n"
                        "@moominAmir"
                    ),
                }
                try:
                    await context.bot.send_message(chat_id=user_id, text=messages.get(milestone, ""))
                except Exception:
                    pass
            # ×”×ª×¨××” ×œ××“××™×Ÿ ×œ××™×œ×¡×˜×•× ×™× ××©××¢×•×ª×™×™× (500+) â€” ×’× ×× ×›×‘×¨ ×¡×•××Ÿ, ×œ× ××¡×•×›×Ÿ ×œ×©×œ×•×— ×¤×¢× × ×•×¡×¤×ª
            if milestone >= 500:
                uname = (username or f"User_{user_id}")
                display = f"@{uname}" if uname and not str(uname).startswith('@') else str(uname)
                await notify_admins(context, f"ğŸ“¢ ××©×ª××© {display} ×”×’×™×¢ ×œÖ¾{milestone} ×¤×¢×•×œ×•×ª ×‘×‘×•×˜")
        except Exception:
            pass

    try:
        jq = getattr(context, "job_queue", None) or getattr(context.application, "job_queue", None)
        if jq is not None:
            # ×”×¨×¦×” ××™×™×“×™×ª ×‘×¨×§×¢ ×œ×œ× ×—×¡×™××”
            jq.run_once(lambda _ctx: context.application.create_task(_milestones_job(update.effective_user.id, update.effective_user.username)), when=0)
        else:
            # fallback: ×™×¦×™×¨×ª ××©×™××” ××¡×™× ×›×¨×•× ×™×ª ×™×©×™×¨×•×ª
            import asyncio as _aio
            _aio.create_task(_milestones_job(update.effective_user.id, update.effective_user.username))
    except Exception:
        pass

# =============================================================================
# MONGODB LOCK MANAGEMENT (FINAL, NO-GUESSING VERSION)
# =============================================================================

LOCK_ID = "code_keeper_bot_lock"
LOCK_COLLECTION = "locks"
LOCK_TIMEOUT_MINUTES = 5

def get_lock_collection():
    """
    ××—×–×™×¨ ××ª ×§×•×œ×§×¦×™×™×ª ×”× ×¢×™×œ×•×ª ×××¡×“ ×”× ×ª×•× ×™×.
    
    Returns:
        pymongo.collection.Collection: ×§×•×œ×§×¦×™×™×ª ×”× ×¢×™×œ×•×ª
    
    Raises:
        SystemExit: ×× ××¡×“ ×”× ×ª×•× ×™× ×œ× ××•×ª×—×œ ×›×¨××•×™
    
    Note:
        ××©×ª××© ×‘××¡×“ ×”× ×ª×•× ×™× ×©×›×‘×¨ × ×‘×—×¨ ×‘-DatabaseManager
    """
    try:
        # Use the already-selected database from DatabaseManager
        selected_db = db.db
        if selected_db is None:
            logger.critical("DatabaseManager.db is not initialized!")
            sys.exit(1)
        # Optional: small debug to help diagnose DB mismatches
        try:
            logger.debug(f"Using DB for locks: {selected_db.name}")
        except Exception:
            pass
        return selected_db[LOCK_COLLECTION]
    except Exception as e:
        logger.critical(f"Failed to get lock collection from DatabaseManager: {e}", exc_info=True)
        sys.exit(1)

# New: ensure TTL index on expires_at so stale locks get auto-removed

def ensure_lock_indexes() -> None:
    """
    ×™×•×¦×¨ ××™× ×“×§×¡ TTL ×¢×œ ×©×“×” expires_at ×œ× ×™×§×•×™ ××•×˜×•××˜×™ ×©×œ × ×¢×™×œ×•×ª ×™×©× ×•×ª.
    
    Note:
        ×× ×™×¦×™×¨×ª ×”××™× ×“×§×¡ × ×›×©×œ×ª, ×”××¢×¨×›×ª ×ª××©×™×š ×œ×¢×‘×•×“ ×œ×œ× TTL ××•×˜×•××˜×™
    """
    try:
        lock_collection = get_lock_collection()
        # TTL based on the absolute expiration time in the document
        lock_collection.create_index("expires_at", expireAfterSeconds=0, name="lock_expires_ttl")
    except Exception as e:
        # Non-fatal; continue without TTL if index creation fails
        logger.warning(f"Could not ensure TTL index for lock collection: {e}")

def cleanup_mongo_lock():
    """
    ×× ×§×” ××ª × ×¢×™×œ×ª MongoDB ×‘×¢×ª ×™×¦×™××” ××”×ª×•×›× ×™×ª.
    
    Note:
        ×¤×•× ×§×¦×™×” ×–×• × ×¨×©××ª ×¢× atexit ×•×¨×¦×” ××•×˜×•××˜×™×ª ×‘×¡×™×•× ×”×ª×•×›× ×™×ª
    """
    try:
        # If DB client is not available, skip quietly
        try:
            if 'db' in globals() and getattr(db, "client", None) is None:
                logger.debug("Mongo client not available during lock cleanup; skipping.")
                return
        except Exception:
            pass

        lock_collection = get_lock_collection()
        pid = os.getpid()
        result = lock_collection.delete_one({"_id": LOCK_ID, "pid": pid})
        if result.deleted_count > 0:
            logger.info(f"Lock '{LOCK_ID}' released successfully by PID: {pid}.")
    except pymongo.errors.InvalidOperation:
        logger.warning("Mongo client already closed; skipping lock cleanup.")
    except Exception as e:
        logger.error(f"Error while releasing MongoDB lock: {e}", exc_info=True)

def manage_mongo_lock():
    """
    ×¨×•×›×© × ×¢×™×œ×” ××‘×•×–×¨×ª ×‘-MongoDB ×›×“×™ ×œ×”×‘×˜×™×— ×©×¨×§ ××•×¤×¢ ××—×“ ×©×œ ×”×‘×•×˜ ×¨×¥.
    
    Returns:
        bool: True ×× ×”× ×¢×™×œ×” × ×¨×›×©×” ×‘×”×¦×œ×—×”, False ××—×¨×ª
    
    Note:
        ×ª×•××š ×‘×”××ª× ×” ×œ×©×—×¨×•×¨ × ×¢×™×œ×” ×§×™×™××ª ×¢×‘×•×¨ blue/green deployments
    """
    try:
        try:
            ensure_lock_indexes()
        except Exception:
            logger.warning("could not ensure lock indexes; continuing")
        lock_collection = get_lock_collection()
        pid = os.getpid()
        now = datetime.now(timezone.utc)
        expires_at = now + timedelta(minutes=LOCK_TIMEOUT_MINUTES)

        # Try to create the lock document
        try:
            lock_collection.insert_one({"_id": LOCK_ID, "pid": pid, "expires_at": expires_at})
            logger.info(f"âœ… MongoDB lock acquired by PID {pid}")
        except DuplicateKeyError:
            # A lock already exists
            # First, attempt immediate takeover if the lock is expired
            while True:
                now = datetime.now(timezone.utc)
                expires_at = now + timedelta(minutes=LOCK_TIMEOUT_MINUTES)

                doc = lock_collection.find_one({"_id": LOCK_ID})
                if doc and doc.get("expires_at") and doc["expires_at"] < now:
                    # Attempt to take over an expired lock
                    result = lock_collection.find_one_and_update(
                        {"_id": LOCK_ID, "expires_at": {"$lt": now}},
                        {"$set": {"pid": pid, "expires_at": expires_at}},
                        return_document=True,
                    )
                    if result:
                        logger.info(f"âœ… MongoDB lock re-acquired by PID {pid} (expired lock)")
                        break
                else:
                    # Not expired: wait and retry instead of exiting to support blue/green deploys
                    max_wait_seconds = int(os.getenv("LOCK_MAX_WAIT_SECONDS", "0"))  # 0 = wait indefinitely
                    retry_interval_seconds = int(os.getenv("LOCK_RETRY_INTERVAL_SECONDS", "5"))

                    if max_wait_seconds > 0:
                        deadline = time.time() + max_wait_seconds
                        while time.time() < deadline:
                            time.sleep(retry_interval_seconds)
                            now = datetime.now(timezone.utc)
                            doc = lock_collection.find_one({"_id": LOCK_ID})
                            if not doc or (doc.get("expires_at") and doc["expires_at"] < now):
                                break
                        # loop will re-check and attempt takeover at the top
                        if time.time() >= deadline:
                            logger.warning("Timeout waiting for existing lock to release. Exiting gracefully.")
                            return False
                    else:
                        # Infinite wait with periodic log
                        logger.warning("Another bot instance is already running (lock present). Waiting for lock releaseâ€¦")
                        time.sleep(retry_interval_seconds)
                        continue
                # If we reach here without breaking, loop will retry
            
        # Ensure lock is released on exit
        atexit.register(cleanup_mongo_lock)
        return True

    except Exception as e:
        logger.error(f"Failed to acquire MongoDB lock: {e}", exc_info=True)
        # Fail-open to not crash the app, but log loudly
        return True

# =============================================================================

class CodeKeeperBot:
    """
    ×”××—×œ×§×” ×”×¨××©×™×ª ×©×œ Code Keeper Bot.
    
    ××—×œ×§×” ×–×• ×× ×”×œ×ª ××ª ×›×œ ×”×¤×•× ×§×¦×™×•× ×œ×™×•×ª ×©×œ ×”×‘×•×˜, ×›×•×œ×œ:
    - ×”×’×“×¨×ª handlers ×œ×¤×§×•×“×•×ª ×•××¡×¨×™×
    - × ×™×”×•×œ ×©×™×—×•×ª ××•×¨×›×‘×•×ª
    - ××™× ×˜×’×¨×¦×™×•×ª ×¢× ×©×™×¨×•×ª×™× ×—×™×¦×•× ×™×™×
    - × ×™×”×•×œ ××¡×“ × ×ª×•× ×™×
    
    Attributes:
        application: ××•×‘×™×™×§×˜ Application ×©×œ python-telegram-bot
        github_handler: ×× ×”×œ ××™× ×˜×’×¨×¦×™×™×ª GitHub
        backup_handler: ×× ×”×œ ××¢×¨×›×ª ×”×’×™×‘×•×™×™×
    """
    
    def __init__(self):
        # ×™×¦×™×¨×ª ×ª×™×§×™×™×” ×–×× ×™×ª ×¢× ×”×¨×©××•×ª ×›×ª×™×‘×”
        DATA_DIR = "/tmp"
        if not os.path.exists(DATA_DIR):
            os.makedirs(DATA_DIR, exist_ok=True)
            
        # ×™×¦×™×¨×ª persistence ×œ×©××™×¨×ª × ×ª×•× ×™× ×‘×™×Ÿ ×”×¤×¢×œ×•×ª
        persistence = PicklePersistence(filepath=f"{DATA_DIR}/bot_data.pickle")
        
        # ×‘××¦×‘ ×‘×“×™×§×•×ª/CI, ×—×œ×§ ××ª×œ×•×™×•×ª ×”×˜×œ×’×¨× (Updater ×¤× ×™××™) ×¢×œ×•×œ×•×ª ×œ×”×™×›×©×œ.
        # × ×©×ª××© ×‘×‘× ××™ ×”×¨×’×™×œ, ×•×× × ×›×©×œ â€“ × ×‘× ×” Application ××™× ×™××œ×™ ×¢× ×˜×•×§×Ÿ ×“××”.
        try:
            self.application = (
                Application.builder()
                .token(config.BOT_TOKEN)
                .defaults(Defaults(parse_mode=ParseMode.HTML))
                .persistence(persistence)
                .post_init(setup_bot_data)
                .build()
            )
        except Exception:
            dummy_token = os.getenv("DUMMY_BOT_TOKEN", "dummy_token")
            # × ×¡×” ×œ×‘× ×•×ª ×œ×œ× persistence/post_init ×›×“×™ ×œ×¢×§×•×£ Updater ×¤× ×™××™
            try:
                self.application = (
                    Application.builder()
                    .token(dummy_token)
                    .defaults(Defaults(parse_mode=ParseMode.HTML))
                    .build()
                )
            except Exception:
                # ×‘× ××™ ×™×“× ×™ ××™× ×™××œ×™: ××•×‘×™×™×§×˜ ×¢× ×”×××©×§×™× ×”×“×¨×•×©×™× ×œ×˜×¡×˜×™×/×¡×‘×™×‘×•×ª ×—×¡×¨×•×ª
                class _MiniApp:
                    def __init__(self):
                        self.handlers = []
                        self.bot_data = {}
                        self._error_handlers = []
                        class _JobQ:
                            def run_once(self, *a, **k):
                                return None
                        self.job_queue = _JobQ()
                    def add_handler(self, *a, **k):
                        self.handlers.append((a, k))
                    def remove_handler(self, *a, **k):
                        return None
                    def add_error_handler(self, *a, **k):
                        self._error_handlers.append((a, k))
                    async def run_polling(self, *a, **k):
                        # Fallback ×©×§×˜: ××™×Ÿ polling ×××™×ª×™; ×××¤×©×¨ start ×œ×œ× ×§×¨×™×¡×”
                        return None
                self.application = _MiniApp()
        self.setup_handlers()
        self.advanced_handlers = AdvancedBotHandlers(self.application)
    
    def setup_handlers(self):
        """×”×’×“×¨×ª ×›×œ ×”-handlers ×©×œ ×”×‘×•×˜ ×‘×¡×“×¨ ×”× ×›×•×Ÿ"""

        # Maintenance gate: if enabled, short-circuit most interactions
        if config.MAINTENANCE_MODE:
            async def maintenance_reply(update: Update, context: ContextTypes.DEFAULT_TYPE):
                try:
                    await (update.callback_query.edit_message_text if getattr(update, 'callback_query', None) else update.message.reply_text)(
                        config.MAINTENANCE_MESSAGE
                    )
                except Exception:
                    pass
                return ConversationHandler.END
            # Catch-all high-priority handlers during maintenance (keep references for clean removal)
            self._maintenance_message_handler = MessageHandler(filters.ALL, maintenance_reply)
            self._maintenance_callback_handler = CallbackQueryHandler(maintenance_reply)
            self.application.add_handler(self._maintenance_message_handler, group=-100)
            self.application.add_handler(self._maintenance_callback_handler, group=-100)
            logger.warning("MAINTENANCE_MODE is ON â€” all updates will receive maintenance message")
            # ××œ ×ª×—×¡×•× ×œ×’××¨×™: ×œ××—×¨ warmup ××•×˜×•××˜×™, ×”×¡×¨ ×ª×—×–×•×§×” (×œ×œ× Redeploy)
            # Schedule removing maintenance handlers via JobQueue instead of create_task
            try:
                warmup_secs = max(1, int(config.MAINTENANCE_AUTO_WARMUP_SECS))
                async def _clear_handlers_cb(context: ContextTypes.DEFAULT_TYPE):
                    try:
                        app = self.application
                        if getattr(self, "_maintenance_message_handler", None) is not None:
                            app.remove_handler(self._maintenance_message_handler, group=-100)
                        if getattr(self, "_maintenance_callback_handler", None) is not None:
                            app.remove_handler(self._maintenance_callback_handler, group=-100)
                        logger.warning("MAINTENANCE_MODE auto-warmup window elapsed; resuming normal operation")
                    except Exception:
                        pass
                self.application.job_queue.run_once(_clear_handlers_cb, when=warmup_secs, name="maintenance_clear_handlers")
            except Exception:
                pass
            # ×××©×™×›×™× ×œ×¨×©×•× ××ª ×©××¨ ×”-handlers ×›×“×™ ×©×™×§×œ×˜×• ××•×˜×•××˜×™×ª ××—×¨×™ ×”-warmup

        # ×¡×¤×•×¨ ××ª ×”-handlers
        handler_count = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ×œ×¤× ×™: {handler_count}")

        # Add conversation handler
        conversation_handler = get_save_conversation_handler(db)
        self.application.add_handler(conversation_handler)
        logger.info("ConversationHandler × ×•×¡×£")

        # ×¡×¤×•×¨ ×©×•×‘
        handler_count_after = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ××—×¨×™: {handler_count_after}")

        # --- GitHub handlers - ×—×™×™×‘×™× ×œ×”×™×•×ª ×œ×¤× ×™ ×”-handler ×”×’×œ×•×‘×œ×™! ---
        # ×™×¦×™×¨×ª instance ×™×—×™×“ ×©×œ GitHubMenuHandler ×•×©××™×¨×” ×‘-bot_data
        github_handler = GitHubMenuHandler()
        self.application.bot_data['github_handler'] = github_handler
        logger.info("âœ… GitHubMenuHandler instance created and stored in bot_data")
        # ×™×¦×™×¨×ª BackupMenuHandler ×•×©××™×¨×”
        backup_handler = BackupMenuHandler()
        self.application.bot_data['backup_handler'] = backup_handler
        logger.info("âœ… BackupMenuHandler instance created and stored in bot_data")

        # ×™×¦×™×¨×ª GoogleDriveMenuHandler ×•×©××™×¨×”
        drive_handler = GoogleDriveMenuHandler()
        self.application.bot_data['drive_handler'] = drive_handler
        logger.info("âœ… GoogleDriveMenuHandler instance created and stored in bot_data")
        
        # ×”×•×¡×£ ×¤×§×•×“×ª github
        self.application.add_handler(CommandHandler("github", github_handler.github_menu_command))
        # ×”×•×¡×£ ×ª×¤×¨×™×˜ ×’×™×‘×•×™/×©×—×–×•×¨
        async def show_backup_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await backup_handler.show_backup_menu(update, context)
        self.application.add_handler(CommandHandler("backup", show_backup_menu))
        self.application.add_handler(CallbackQueryHandler(backup_handler.handle_callback_query, pattern=r'^(backup_|backup_add_note:.*)'))
        
        # ×”×•×¡×£ ××ª ×”-callbacks ×©×œ GitHub - ×—×©×•×‘! ×œ×¤× ×™ ×”-handler ×”×’×œ×•×‘×œ×™
        self.application.add_handler(
                        CallbackQueryHandler(github_handler.handle_menu_callback, 
                               pattern=r'^(select_repo|upload_file|upload_saved|show_current|set_token|set_folder|close_menu|folder_|repo_|repos_page_|upload_saved_|back_to_menu|repo_manual|noop|analyze_repo|analyze_current_repo|analyze_other_repo|show_suggestions|show_full_analysis|download_analysis_json|back_to_analysis|back_to_analysis_menu|back_to_summary|choose_my_repo|enter_repo_url|suggestion_\d+|github_menu|logout_github|delete_file_menu|delete_repo_menu|confirm_delete_repo|confirm_delete_repo_step1|confirm_delete_file|danger_delete_menu|download_file_menu|browse_repo|browse_open:.*|browse_select_download:.*|browse_select_delete:.*|browse_page:.*|download_zip:.*|multi_toggle|multi_execute|multi_clear|safe_toggle|browse_toggle_select:.*|inline_download_file:.*|view_more|view_back|browse_select_view:.*|browse_ref_menu|browse_refs_branches_page_.*|browse_refs_tags_page_.*|browse_select_ref:.*|browse_search|browse_search_page:.*|notifications_menu|notifications_toggle|notifications_toggle_pr|notifications_toggle_issues|notifications_interval_.*|notifications_check_now|share_folder_link:.*|share_selected_links|pr_menu|create_pr_menu|branches_page_.*|pr_select_head:.*|confirm_create_pr|merge_pr_menu|prs_page_.*|merge_pr:.*|confirm_merge_pr|validate_repo|git_checkpoint|git_checkpoint_doc:.*|git_checkpoint_doc_skip|restore_checkpoint_menu|restore_tags_page_.*|restore_select_tag:.*|restore_branch_from_tag:.*|restore_revert_pr_from_tag:.*|open_pr_from_branch:.*|choose_upload_branch|upload_branches_page_.*|upload_select_branch:.*|choose_upload_folder|upload_select_folder:.*|upload_folder_root|upload_folder_current|upload_folder_custom|upload_folder_create|create_folder|confirm_saved_upload|refresh_saved_checks|github_backup_menu|github_backup_help|github_backup_db_list|github_restore_zip_to_repo|github_restore_zip_setpurge:.*|github_restore_zip_list|github_restore_zip_from_backup:.*|github_repo_restore_backup_setpurge:.*|gh_upload_cat:.*|gh_upload_repo:.*|gh_upload_large:.*|backup_menu|github_create_repo_from_zip|github_new_repo_name|github_set_new_repo_visibility:.*|upload_paste_code|cancel_paste_flow|gh_upload_zip_browse:.*|gh_upload_zip_page:.*|gh_upload_zip_select:.*|gh_upload_zip_select_idx:.*|backup_add_note:.*|github_import_repo|import_repo_branches_page_.*|import_repo_select_branch:.*|import_repo_start|import_repo_cancel)')
            )

        # ×”×•×¡×£ ××ª ×”-callbacks ×©×œ Google Drive
        self.application.add_handler(
            CallbackQueryHandler(
                drive_handler.handle_callback,
                pattern=r'^(drive_menu|drive_auth|drive_poll_once|drive_cancel_auth|drive_backup_now|drive_sel_zip|drive_sel_all|drive_sel_adv|drive_advanced|drive_adv_by_repo|drive_adv_large|drive_adv_other|drive_choose_folder|drive_choose_folder_adv|drive_folder_default|drive_folder_auto|drive_folder_set|drive_folder_back|drive_folder_cancel|drive_schedule|drive_set_schedule:.*|drive_status|drive_adv_multi_toggle|drive_adv_upload_selected|drive_logout|drive_logout_do|drive_simple_confirm|drive_adv_confirm|drive_make_zip_now|drive_help)$'
            )
        )

        # Inline query handler
        self.application.add_handler(InlineQueryHandler(github_handler.handle_inline_query))
        
        # ×”×’×“×¨ conversation handler ×œ×”×¢×œ××ª ×§×‘×¦×™×
        from github_menu_handler import FILE_UPLOAD, REPO_SELECT, FOLDER_SELECT
        upload_conv_handler = ConversationHandler(
            entry_points=[
                CallbackQueryHandler(github_handler.handle_menu_callback, pattern='^upload_file$')
            ],
            states={
                FILE_UPLOAD: [
                    MessageHandler(filters.Document.ALL, github_handler.handle_file_upload)
                ],
                REPO_SELECT: [
                    MessageHandler(filters.TEXT & ~filters.COMMAND, github_handler.handle_text_input)
                ],
                FOLDER_SELECT: [
                    MessageHandler(filters.TEXT & ~filters.COMMAND, github_handler.handle_text_input)
                ]
            },
            fallbacks=[CommandHandler('cancel', lambda u, c: ConversationHandler.END)]
        )
        
        self.application.add_handler(upload_conv_handler)
        
        # ×”×•×¡×£ handler ×›×œ×œ×™ ×œ×˜×™×¤×•×œ ×‘×§×œ×˜ ×˜×§×¡×˜ ×©×œ GitHub (×›×•×œ×œ URL ×œ× ×™×ª×•×—)
        async def handle_github_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
            # ×”×¢×‘×¨ ×›×œ ×§×œ×˜ ×¨×œ×•×•× ×˜×™ ×œ×× ×”×œ GitHub ×œ×¤×™ ×“×’×œ×™× ×‘-user_data
            text = (update.message.text or '').strip()
            main_menu_texts = {"â• ×”×•×¡×£ ×§×•×“ ×—×“×©", "ğŸ“š ×”×¦×’ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×™", "ğŸ“‚ ×§×‘×¦×™× ×’×“×•×œ×™×", "ğŸ”§ GitHub", "ğŸ  ×ª×¤×¨×™×˜ ×¨××©×™", "âš¡ ×¢×™×‘×•×“ Batch"}
            if text in main_menu_texts:
                # × ×§×” ×“×’×œ×™× ×›×“×™ ×œ×× ×•×¢ ×˜×¨×™×’×¨ ×©×’×•×™
                context.user_data.pop('waiting_for_repo_url', None)
                context.user_data.pop('waiting_for_delete_file_path', None)
                context.user_data.pop('waiting_for_download_file_path', None)
                context.user_data.pop('waiting_for_new_repo_name', None)
                context.user_data.pop('waiting_for_selected_folder', None)
                context.user_data.pop('waiting_for_new_folder_path', None)
                context.user_data.pop('waiting_for_upload_folder', None)
                context.user_data.pop('return_to_pre_upload', None)
                # × ×§×” ×’× ×“×’×œ×™ "×”×“×‘×§ ×§×•×“" ×›×“×™ ×œ×¦××ª ×™×¤×” ××”×–×¨×™××”
                context.user_data.pop('waiting_for_paste_content', None)
                context.user_data.pop('waiting_for_paste_filename', None)
                context.user_data.pop('paste_content', None)
                return False
            # ×–×¨×™××ª ×”×•×¡×¤×ª ×”×¢×¨×” ×œ×’×™×‘×•×™ (××©×•×ª×¤×ª ×œ-GitHub/Backup)
            if context.user_data.get('waiting_for_backup_note_for'):
                backup_id = context.user_data.pop('waiting_for_backup_note_for')
                try:
                    from database import db
                    ok = db.save_backup_note(update.effective_user.id, backup_id, (text or '')[:1000])
                    if ok:
                        await update.message.reply_text(
                            "âœ… ×”×”×¢×¨×” × ×©××¨×”!",
                            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ”™ ×—×–×¨×”", callback_data=f"backup_details:{backup_id}")]])
                        )
                        # ×× ×¢ ×”×•×“×¢×ª "× ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!" ×¢×‘×•×¨ ×”×”×•×“×¢×” ×”×–×•
                        context.user_data['suppress_code_hint_once'] = True
                    else:
                        await update.message.reply_text("âŒ ×©××™×¨×ª ×”×”×¢×¨×” × ×›×©×œ×”")
                except Exception as e:
                    await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×”×¢×¨×”: {e}")
                return True
            if context.user_data.get('waiting_for_repo_url') or \
               context.user_data.get('waiting_for_delete_file_path') or \
               context.user_data.get('waiting_for_download_file_path') or \
               context.user_data.get('waiting_for_new_repo_name') or \
               context.user_data.get('waiting_for_selected_folder') or \
               context.user_data.get('waiting_for_new_folder_path') or \
               context.user_data.get('waiting_for_paste_content') or \
               context.user_data.get('waiting_for_paste_filename') or \
               context.user_data.get('browse_search_mode'):
                logger.info(f"ğŸ”— Routing GitHub-related text input from user {update.effective_user.id}")
                return await github_handler.handle_text_input(update, context)
            return False
        
        # ×”×•×¡×£ ××ª ×”-handler ×¢× ×¢×“×™×¤×•×ª ×’×‘×•×”×”
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_github_text),
            group=-1  # ×¢×“×™×¤×•×ª ×’×‘×•×”×” ×××•×“
        )
        # ×”×•×¡×£ handler ×˜×§×¡×˜ ×œ-Drive (×§×•×“ ××™×©×•×¨)
        async def handle_drive_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
            return await drive_handler.handle_text(update, context)

        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, handle_drive_text),
            group=-1
        )

        
        logger.info("âœ… GitHub handler × ×•×¡×£ ×‘×”×¦×œ×—×”")
        
        # Handler × ×¤×¨×“ ×œ×˜×™×¤×•×œ ×‘×˜×•×§×Ÿ GitHub
        async def handle_github_token(update: Update, context: ContextTypes.DEFAULT_TYPE):
            text = update.message.text
            if text.startswith('ghp_') or text.startswith('github_pat_'):
                user_id = update.message.from_user.id
                if user_id not in github_handler.user_sessions:
                    github_handler.user_sessions[user_id] = {}
                # ×©××™×¨×” ×‘×–×™×›×¨×•×Ÿ ×‘×œ×‘×“ ×œ×©×™××•×© ×©×•×˜×£
                github_handler.user_sessions[user_id]['github_token'] = text
                
                # ×©××•×¨ ×’× ×‘××¡×“ × ×ª×•× ×™× (×¢× ×”×¦×¤× ×” ×× ××•×’×“×¨ ××¤×ª×—)
                db.save_github_token(user_id, text)
                
                await update.message.reply_text(
                    "âœ… ×˜×•×§×Ÿ × ×©××¨ ×‘×”×¦×œ×—×”!\n"
                    "×›×¢×ª ×ª×•×›×œ ×œ×’×©×ª ×œ×¨×™×¤×•×–×™×˜×•×¨×™×– ×”×¤×¨×˜×™×™× ×©×œ×š.\n\n"
                    "×©×œ×— /github ×›×“×™ ×œ×—×–×•×¨ ×œ×ª×¤×¨×™×˜."
                )
                return
        
        # ×”×•×¡×£ ××ª ×”-handler
        self.application.add_handler(
            MessageHandler(filters.Regex('^(ghp_|github_pat_)'), handle_github_token),
            group=0  # ×¢×“×™×¤×•×ª ×’×‘×•×”×”
        )
        logger.info("âœ… GitHub token handler × ×•×¡×£ ×‘×”×¦×œ×—×”")

        # ×¤×§×•×“×” ×œ××—×™×§×ª ×˜×•×§×Ÿ GitHub
        async def handle_github_logout(update: Update, context: ContextTypes.DEFAULT_TYPE):
            user_id = update.effective_user.id
            # ××—×™×§×” ××”××¡×“ × ×ª×•× ×™×
            removed = db.delete_github_token(user_id)
            # × ×™×§×•×™ ××”×¡×©×Ÿ
            try:
                session = github_handler.get_user_session(user_id)
                session["github_token"] = None
                session['selected_repo'] = None
                session['selected_folder'] = None
            except Exception:
                pass
            # × ×™×§×•×™ ×§××© ×¨×™×¤×•×–×™×˜×•×¨×™×–
            context.user_data.pop('repos', None)
            context.user_data.pop('repos_cache_time', None)
            if removed:
                await update.message.reply_text("ğŸ” ×”×˜×•×§×Ÿ × ××—×§ ×‘×”×¦×œ×—×” ××”×—×©×‘×•×Ÿ ×©×œ×š.\nâœ… ×”×•×¡×¨×• ×’× ×”×’×“×¨×•×ª ×¨×™×¤×•/×ª×™×§×™×™×”.")
            else:
                await update.message.reply_text("â„¹ï¸ ×œ× × ××¦× ×˜×•×§×Ÿ ×œ×©×—×–×•×¨ ××• ×©××™×¨×¢×” ×©×’×™××”.")

        self.application.add_handler(CommandHandler("github_logout", handle_github_logout))

        # --- Guard ×’×œ×•×‘×œ×™ ×œ×œ×—×™×¦×•×ª ×›×¤×•×œ×•×ª ×¢×œ CallbackQuery (×§×“×™××•×ª ×’×‘×•×”×” ×‘×™×•×ª×¨) ---
        async def _global_callback_guard(update: Update, context: ContextTypes.DEFAULT_TYPE):
            try:
                if getattr(update, 'callback_query', None):
                    # ×‘×“×™×§×ª ×“×•×¤×œ×™×§×˜×™× ×§×¦×¨×” ×œ×›×œ ×”×›×¤×ª×•×¨×™×
                    try:
                        from utils import CallbackQueryGuard
                        if await CallbackQueryGuard.should_block_async(update, context):
                            try:
                                await update.callback_query.answer()
                            except Exception:
                                pass
                            # ×¢×¦×•×¨ ×¢×™×‘×•×“ × ×•×¡×£ ×©×œ ×”×”×•×“×¢×” ×”× ×•×›×—×™×ª
                            raise ApplicationHandlerStop()
                    except Exception:
                        pass
            except ApplicationHandlerStop:
                raise
            except Exception:
                pass

        # ×”×•×¡×£ ××ª ×”-guard ×‘×§×‘×•×¦×” ×‘×¢×œ×ª ×¢×“×™×¤×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨, ×œ×¤× ×™ ×›×œ ×”-handlers (×›×•×œ×œ batch/github/drive)
        self.application.add_handler(CallbackQueryHandler(_global_callback_guard), group=-100)

        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª batch (×¢×™×‘×•×“ ××¨×•×‘×” ×§×‘×¦×™×) ×œ××—×¨ ×”-guard ×›×š ×©×œ× ×™×¢×§×•×£ ××•×ª×•
        setup_batch_handlers(self.application)

        # --- ×¨×§ ××—×¨×™ ×›×œ ×”-handlers ×”×¡×¤×¦×™×¤×™×™×, ×”×•×¡×£ ××ª ×”-handler ×”×’×œ×•×‘×œ×™ ---
        from conversation_handlers import handle_callback_query
        self.application.add_handler(CallbackQueryHandler(handle_callback_query))
        logger.info("CallbackQueryHandler ×’×œ×•×‘×œ×™ × ×•×¡×£")

        # ×¡×¤×•×¨ ×¡×•×¤×™
        final_handler_count = len(self.application.handlers)
        logger.info(f"ğŸ” ×›××•×ª handlers ×¡×•×¤×™×ª: {final_handler_count}")

        # ×”×“×¤×¡ ××ª ×›×œ ×”-handlers
        for i, handler in enumerate(self.application.handlers):
            logger.info(f"Handler {i}: {type(handler).__name__}")

        # --- ×©×œ×‘ 2: ×¨×™×©×•× ×©××¨ ×”×¤×§×•×“×•×ª ---
        # ×¤×§×•×“×ª ×× ×”×œ×™×: recycle_backfill
        self.application.add_handler(CommandHandler("recycle_backfill", recycle_backfill_command))
        # ×”×¤×§×•×“×” /start ×”××§×•×¨×™×ª ×”×•×¤×›×ª ×œ×”×™×•×ª ×—×œ×§ ××”-conv_handler, ××– ×”×™× ×œ× ×›××Ÿ.
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(CommandHandler("save", self.save_command))
        # self.application.add_handler(CommandHandler("list", self.list_command))  # ××—×•×§ - ××˜×•×¤×œ ×¢×œ ×™×“×™ ×”×›×¤×ª×•×¨ "ğŸ“š ×”×¦×’ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×™"
        self.application.add_handler(CommandHandler("search", self.search_command))
        self.application.add_handler(CommandHandler("stats", self.stats_command))
        self.application.add_handler(CommandHandler("check", self.check_commands))
        
        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª cache
        setup_cache_handlers(self.application)
        
        # ×”×•×¡×¤×ª ×¤×§×•×“×•×ª ××©×•×¤×¨×•×ª (××•×˜×•-×”×©×œ××” ×•×ª×¦×•×’×” ××§×“×™××”) - disabled
        # setup_enhanced_handlers(self.application)

        # ×”×˜×¨××™× ×œ ×”×•×¡×¨ ×‘×¡×‘×™×‘×ª Render (Docker ×œ× ×–××™×Ÿ)


        # ×”×•×¡×¤×ª handlers ×œ×›×¤×ª×•×¨×™× ×”×—×“×©×™× ×‘××§×œ×“×ª ×”×¨××©×™×ª
        from conversation_handlers import handle_batch_button
        self.application.add_handler(MessageHandler(
            filters.Regex("^âš¡ ×¢×™×‘×•×“ Batch$"), 
            handle_batch_button
        ))
        # ×›×¤×ª×•×¨ ×œ×ª×¤×¨×™×˜ Google Drive
        async def show_drive_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await drive_handler.menu(update, context)
        self.application.add_handler(MessageHandler(
            filters.Regex("^â˜ï¸ Google Drive$"),
            show_drive_menu
        ))

        # ×¤×§×•×“×” /drive
        self.application.add_handler(CommandHandler("drive", show_drive_menu))
        
        # ×›×¤×ª×•×¨ Web App
        async def show_webapp(update: Update, context: ContextTypes.DEFAULT_TYPE):
            webapp_url = os.getenv('WEBAPP_URL', 'https://code-keeper-webapp.onrender.com')
            keyboard = [
                [InlineKeyboardButton("ğŸŒ ×¤×ª×— ××ª ×”-Web App", url=webapp_url)],
                [InlineKeyboardButton("ğŸ” ×”×ª×—×‘×¨ ×œ-Web App", url=f"{webapp_url}/login")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await update.message.reply_text(
                "ğŸŒ <b>Web App - ×××©×§ × ×™×”×•×œ ××ª×§×“×</b>\n\n"
                "×¦×¤×” ×•× ×”×œ ××ª ×›×œ ×”×§×‘×¦×™× ×©×œ×š ×“×¨×š ×”×“×¤×“×¤×Ÿ:\n"
                "â€¢ ğŸ“Š ×“×©×‘×•×¨×“ ×¢× ×¡×˜×˜×™×¡×˜×™×§×•×ª\n"
                "â€¢ ğŸ” ×—×™×¤×•×© ×•×¡×™× ×•×Ÿ ××ª×§×“×\n"
                "â€¢ ğŸ‘ï¸ ×¦×¤×™×™×” ×‘×§×‘×¦×™× ×¢× ×”×“×’×©×ª syntax\n"
                "â€¢ ğŸ“¥ ×”×•×¨×“×ª ×§×‘×¦×™×\n"
                "â€¢ ğŸ“± ×¢×•×‘×“ ×‘×›×œ ××›×©×™×¨\n\n"
                "×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×œ××˜×” ×›×“×™ ×œ×¤×ª×•×—:",
                reply_markup=reply_markup,
                parse_mode=ParseMode.HTML
            )
        
        self.application.add_handler(MessageHandler(
            filters.Regex("^ğŸŒ Web App$"),
            show_webapp
        ))
        
        # ×¤×§×•×“×” /webapp
        self.application.add_handler(CommandHandler("webapp", show_webapp))
        
        # ×›×¤×ª×•×¨ ×—×“×© ×œ×ª×¤×¨×™×˜ ×’×™×‘×•×™/×©×—×–×•×¨

        # ×¤×§×•×“×” /docs â€“ ×©×œ×™×—×ª ×§×™×©×•×¨ ×œ×ª×™×¢×•×“
        async def show_docs(update: Update, context: ContextTypes.DEFAULT_TYPE):
            await update.message.reply_text(f"ğŸ“š ×ª×™×¢×•×“: {config.DOCUMENTATION_URL}")
        self.application.add_handler(CommandHandler("docs", show_docs))
        # ×”×•×¡×¨: ×›×¤×ª×•×¨×™ ×’×™×‘×•×™/×©×—×–×•×¨ ××”××§×œ×“×ª ×”×¨××©×™×ª. ×›×¢×ª ×ª×—×ª /github -> ğŸ§° ×’×™×‘×•×™ ×•×©×—×–×•×¨
        # self.application.add_handler(MessageHandler(
        #     filters.Regex("^(ğŸ“¦ ×’×™×‘×•×™ ××œ×|â™»ï¸ ×©×—×–×•×¨ ××’×™×‘×•×™|ğŸ§° ×’×™×‘×•×™/×©×—×–×•×¨)$"),
        #     show_backup_menu
        # ))
        
        # --- ×©×œ×‘ 3: ×¨×™×©×•× handler ×œ×§×‘×¦×™× ---
        self.application.add_handler(
            MessageHandler(filters.Document.ALL, self.handle_document)
        )
        
        # --- ×©×œ×‘ 4: ×¨×™×©×•× ×”××˜×¤×œ ×”×›×œ×œ×™ ×‘×¡×•×£ ---
        # ×”×•× ×™×¤×¢×œ ×¨×§ ×× ××£ ××—×“ ××”××˜×¤×œ×™× ×”×¡×¤×¦×™×¤×™×™× ×™×•×ª×¨ ×œ× ×ª×¤×¡ ××ª ×”×”×•×“×¢×”.
        self.application.add_handler(
            MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text_message)
        )
        
        # --- ×©×œ×‘ 5: ×˜×™×¤×•×œ ×‘×©×’×™××•×ª ---
        self.application.add_error_handler(self.error_handler)
    
    # start_command ×”×•×¡×¨ - ConversationHandler ××˜×¤×œ ×‘×¤×§×•×“×ª /start
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª ×¢×–×¨×” ××¤×•×¨×˜×ª"""
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        response = """
ğŸ“š <b>×¨×©×™××ª ×”×¤×§×•×“×•×ª ×”××œ××”:</b>

<b>×©××™×¨×” ×•× ×™×”×•×œ:</b>
â€¢ <code>/save &lt;filename&gt;</code> - ×”×ª×—×œ×ª ×©××™×¨×” ×©×œ ×§×•×‘×¥ ×—×“×©.
â€¢ <code>/list</code> - ×”×¦×’×ª ×›×œ ×”×§×‘×¦×™× ×©×œ×š.
â€¢ <code>/show &lt;filename&gt;</code> - ×”×¦×’×ª ×§×•×‘×¥ ×¢× ×”×“×’×©×ª ×ª×—×‘×™×¨ ×•×›×¤×ª×•×¨×™ ×¤×¢×•×œ×”.
â€¢ <code>/edit &lt;filename&gt;</code> - ×¢×¨×™×›×ª ×§×•×“ ×©×œ ×§×•×‘×¥ ×§×™×™×.
â€¢ <code>/delete &lt;filename&gt;</code> - ××—×™×§×ª ×§×•×‘×¥.
â€¢ <code>/rename &lt;old&gt; &lt;new&gt;</code> - ×©×™× ×•×™ ×©× ×§×•×‘×¥.
â€¢ <code>/download &lt;filename&gt;</code> - ×”×•×¨×“×ª ×§×•×‘×¥ ×›××¡××š.
â€¢ <code>/github</code> - ×ª×¤×¨×™×˜ ×”×¢×œ××” ×œ-GitHub.
    
<b>×—×™×¤×•×© ×•×¡×™× ×•×Ÿ:</b>
â€¢ <code>/recent</code> - ×”×¦×’×ª ×§×‘×¦×™× ×©×¢×•×“×›× ×• ×œ××—×¨×•× ×”.
â€¢ <code>/stats</code> - ×¡×˜×˜×™×¡×˜×™×§×•×ª ××™×©×™×•×ª.
â€¢ <code>/tags &lt;filename&gt; &lt;tag1&gt;,&lt;tag2&gt;</code> - ×”×•×¡×¤×ª ×ª×’×™×•×ª ×œ×§×•×‘×¥.
â€¢ <code>/search &lt;query&gt;</code> - ×—×™×¤×•×© ×˜×§×¡×˜×•××œ×™ ×‘×§×•×“ ×©×œ×š.
    
<b>×¤×™×¦'×¨×™× ×—×“×©×™×:</b>
â€¢ <code>/autocomplete &lt;×—×œ×§_××©×&gt;</code> - ××•×˜×•-×”×©×œ××” ×œ×©××•×ª ×§×‘×¦×™×.
â€¢ <code>/preview &lt;filename&gt;</code> - ×ª×¦×•×’×” ××§×“×™××” ×©×œ ×§×•×“ (15 ×©×•×¨×•×ª ×¨××©×•× ×•×ª).
â€¢ <code>/info &lt;filename&gt;</code> - ××™×“×¢ ××”×™×¨ ×¢×œ ×§×•×‘×¥ ×œ×œ× ×¤×ª×™×—×”.
â€¢ <code>/large &lt;filename&gt;</code> - ×”×¦×’×ª ×§×•×‘×¥ ×’×“×•×œ ×¢× × ×™×•×•×˜ ×‘×—×œ×§×™×.

<b>×¢×™×‘×•×“ Batch (××¨×•×‘×” ×§×‘×¦×™×):</b>
â€¢ <code>/batch_analyze all</code> - × ×™×ª×•×— ×›×œ ×”×§×‘×¦×™× ×‘×•-×–×× ×™×ª.
â€¢ <code>/batch_analyze python</code> - × ×™×ª×•×— ×§×‘×¦×™ ×©×¤×” ×¡×¤×¦×™×¤×™×ª.
â€¢ <code>/batch_validate all</code> - ×‘×“×™×§×ª ×ª×§×™× ×•×ª ××¨×•×‘×” ×§×‘×¦×™×.
â€¢ <code>/job_status</code> - ×‘×“×™×§×ª ×¡×˜×˜×•×¡ ×¢×‘×•×“×•×ª ×‘×¨×§×¢.

<b>×‘×™×¦×•×¢×™× ×•×ª×—×–×•×§×”:</b>
â€¢ <code>/cache_stats</code> - ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×™×¦×•×¢×™ cache.
â€¢ <code>/clear_cache</code> - × ×™×§×•×™ cache ××™×©×™ ×œ×©×™×¤×•×¨ ×‘×™×¦×•×¢×™×.

<b>××™×“×¢ ×›×œ×œ×™:</b>
â€¢ <code>/recent</code> - ×”×¦×’×ª ×§×‘×¦×™× ×©×¢×•×“×›× ×• ×œ××—×¨×•× ×”.
â€¢ <code>/help</code> - ×”×¦×’×ª ×”×•×“×¢×” ×–×•.

ğŸ”§ <b>×œ×›×œ ×ª×§×œ×” ×‘×‘×•×˜ × × ×œ×©×œ×•×— ×”×•×“×¢×” ×œ-@moominAmir</b>
"""
        await update.message.reply_text(response, parse_mode=ParseMode.HTML)
    
    async def save_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª ×©××™×¨×ª ×§×•×“"""
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        
        if not context.args:
            await update.message.reply_text(
                "â“ ×× × ×¦×™×™×Ÿ ×©× ×§×•×‘×¥:\n"
                "×“×•×’××”: `/save script.py`\n"
                "×¢× ×ª×’×™×•×ª: `/save script.py #python #api`",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        # ×¤×¨×¡×•×¨ ×©× ×§×•×‘×¥ ×•×ª×’×™×•×ª
        args = " ".join(context.args)
        tags = []
        
        # ×—×™×œ×•×¥ ×ª×’×™×•×ª
        import re
        tag_matches = re.findall(r'#(\w+)', args)
        if tag_matches:
            tags = tag_matches
            # ×”×¡×¨×ª ×”×ª×’×™×•×ª ××©× ×”×§×•×‘×¥
            args = re.sub(r'#\w+', '', args).strip()
        
        file_name = args
        
        # ×©××™×¨×ª ××™×“×¢ ×‘×”×§×©×¨ ×œ××©×š ×”×©×™×—×”
        context.user_data['saving_file'] = {
            'file_name': file_name,
            'tags': tags,
            'user_id': user_id
        }
        
        safe_file_name = html_escape(file_name)
        safe_tags = ", ".join(html_escape(t) for t in tags) if tags else '×œ×œ×'
        
        # ×‘×§×©×ª ×§×•×“ ×•×œ××—×¨×™×• ×”×¢×¨×” ××•×¤×¦×™×•× ×œ×™×ª
        await update.message.reply_text(
            f"ğŸ“ ××•×›×Ÿ ×œ×©××•×¨ ××ª <code>{safe_file_name}</code>\n"
            f"ğŸ·ï¸ ×ª×’×™×•×ª: {safe_tags}\n\n"
            "×× × ×©×œ×— ××ª ×§×˜×¢ ×”×§×•×“:\n"
            "(××—×¨×™ ×©× ×§×‘×œ ××ª ×”×§×•×“, ××©××œ ×× ×ª×¨×¦×” ×œ×”×•×¡×™×£ ×”×¢×¨×”)",
            parse_mode=ParseMode.HTML
        )
    
    async def list_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×”×¦×’×ª ×¨×©×™××ª ×”×§×˜×¢×™× ×©×œ ×”××©×ª××©"""
        reporter.report_activity(update.effective_user.id)
        user_id = update.effective_user.id
        
        files = db.get_user_files(user_id, limit=20)
        
        if not files:
            await update.message.reply_text(
                "ğŸ“‚ ×¢×“×™×™×Ÿ ×œ× ×©××¨×ª ×§×˜×¢×™ ×§×•×“.\n"
                "×”×©×ª××© ×‘/save ×›×“×™ ×œ×”×ª×—×™×œ!"
            )
            return
        
        # ×‘× ×™×™×ª ×”×¨×©×™××”
        response = "ğŸ“‹ **×”×§×˜×¢×™× ×©×œ×š:**\n\n"
        
        for i, file_data in enumerate(files, 1):
            tags_str = ", ".join(file_data.get('tags', [])) if file_data.get('tags') else ""
            description = file_data.get('description', '')
            
            response += f"**{i}. {file_data['file_name']}**\n"
            response += f"ğŸ”¤ ×©×¤×”: {file_data['programming_language']}\n"
            
            if description:
                response += f"ğŸ“ ×ª×™××•×¨: {description}\n"
            
            if tags_str:
                response += f"ğŸ·ï¸ ×ª×’×™×•×ª: {tags_str}\n"
            
            response += f"ğŸ“… ×¢×•×“×›×Ÿ: {file_data['updated_at'].strftime('%d/%m/%Y %H:%M')}\n"
            response += f"ğŸ”¢ ×’×¨×¡×”: {file_data['version']}\n\n"
        
        if len(files) == 20:
            response += "\nğŸ“„ ××•×¦×’×™× 20 ×”×§×˜×¢×™× ×”××—×¨×•× ×™×. ×”×©×ª××© ×‘×—×™×¤×•×© ×œ×¢×•×“..."
        
        await update.message.reply_text(response, parse_mode=ParseMode.HTML)
    
    async def search_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×—×™×¤×•×© ×§×˜×¢×™ ×§×•×“"""
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        
        if not context.args:
            await update.message.reply_text(
                "ğŸ” **××™×š ×œ×—×¤×©:**\n"
                "â€¢ `/search python` - ×œ×¤×™ ×©×¤×”\n"
                "â€¢ `/search api` - ×—×™×¤×•×© ×—×•×¤×©×™\n"
                "â€¢ `/search #automation` - ×œ×¤×™ ×ª×’×™×ª\n"
                "â€¢ `/search script` - ×‘×©× ×§×•×‘×¥",
                parse_mode=ParseMode.MARKDOWN
            )
            return
        
        query = " ".join(context.args)
        
        # ×–×™×”×•×™ ×× ×–×” ×—×™×¤×•×© ×œ×¤×™ ×ª×’×™×ª
        tags = []
        if query.startswith('#'):
            tags = [query[1:]]
            query = ""
        elif query in config.SUPPORTED_LANGUAGES:
            # ×—×™×¤×•×© ×œ×¤×™ ×©×¤×”
            results = db.search_code(user_id, "", programming_language=query)
        else:
            # ×—×™×¤×•×© ×—×•×¤×©×™
            results = db.search_code(user_id, query, tags=tags)
        
        if not results:
            await update.message.reply_text(
                f"ğŸ” ×œ× × ××¦××• ×ª×•×¦××•×ª ×¢×‘×•×¨: <code>{html_escape(' '.join(context.args))}</code>",
                parse_mode=ParseMode.HTML
            )
            return
        
        # ×”×¦×’×ª ×ª×•×¦××•×ª
        safe_query = html_escape(' '.join(context.args))
        response = f"ğŸ” **×ª×•×¦××•×ª ×—×™×¤×•×© ×¢×‘×•×¨:** <code>{safe_query}</code>\n\n"
        
        for i, file_data in enumerate(results[:10], 1):
            response += f"{i}. <code>{html_escape(file_data['file_name'])}</code> â€” {file_data['programming_language']}\n"
        
        if len(results) > 10:
            response += f"\nğŸ“„ ××•×¦×’×•×ª 10 ××ª×•×š {len(results)} ×ª×•×¦××•×ª"
        
        await update.message.reply_text(response, parse_mode=ParseMode.HTML)
    
    async def check_commands(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×‘×“×™×§×ª ×”×¤×§×•×“×•×ª ×”×–××™× ×•×ª (×¨×§ ×œ×××™×¨)"""
        
        if update.effective_user.id != 6865105071:
            return
        
        # ×‘×“×•×§ ×¤×§×•×“×•×ª ×¦×™×‘×•×¨×™×•×ª
        public_cmds = await context.bot.get_my_commands()
        
        # ×‘×“×•×§ ×¤×§×•×“×•×ª ××™×©×™×•×ª
        from telegram import BotCommandScopeChat
        personal_cmds = await context.bot.get_my_commands(
            scope=BotCommandScopeChat(chat_id=6865105071)
        )
        
        from html import escape as html_escape

        message = "ğŸ“‹ <b>×¡×˜×˜×•×¡ ×¤×§×•×“×•×ª</b>\n\n"
        message += f"×¡×™×›×•×: ×¦×™×‘×•×¨×™×•×ª {len(public_cmds)} | ××™×©×™×•×ª {len(personal_cmds)}\n\n"
        if public_cmds:
            public_list = "\n".join(f"/{cmd.command}" for cmd in public_cmds)
            message += "<b>×¦×™×‘×•×¨×™×•×ª:</b>\n" + f"<pre>{html_escape(public_list)}</pre>\n"
        if personal_cmds:
            personal_list = "\n".join(f"/{cmd.command} â€” {cmd.description}" for cmd in personal_cmds)
            message += "<b>××™×©×™×•×ª:</b>\n" + f"<pre>{html_escape(personal_list)}</pre>"
        
        await update.message.reply_text(message, parse_mode=ParseMode.HTML)

    async def stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×”×¦×’×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×”××©×ª××© ××• ×× ×”×œ"""
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        user_id = update.effective_user.id
        
        # ×¨×©×™××ª ×× ×”×œ×™×
        ADMIN_IDS = [6865105071]  # ×”×•×¡×£ ××ª ×”-ID ×©×œ×š ×›××Ÿ!
        
        # ×× ×”××©×ª××© ×”×•× ×× ×”×œ, ×”×¦×’ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×× ×”×œ
        if user_id in ADMIN_IDS:
            # ×§×‘×œ ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
            general_stats = user_stats.get_all_time_stats()
            weekly_users = user_stats.get_weekly_stats()
            
            # ×‘× ×” ×”×•×“×¢×” ×‘×˜×•×—×” ×œ-HTML
            message = "ğŸ“Š <b>×¡×˜×˜×™×¡×˜×™×§×•×ª ×× ×”×œ - ×©×‘×•×¢ ××—×¨×•×Ÿ:</b>\n\n"
            message += f"ğŸ‘¥ ×¡×”×´×› ××©×ª××©×™× ×¨×©×•××™×: {general_stats['total_users']}\n"
            message += f"ğŸŸ¢ ×¤×¢×™×œ×™× ×”×™×•×: {general_stats['active_today']}\n"
            message += f"ğŸ“… ×¤×¢×™×œ×™× ×”×©×‘×•×¢: {general_stats['active_week']}\n\n"
            
            if weekly_users:
                message += "ğŸ“‹ <b>×¨×©×™××ª ××©×ª××©×™× ×¤×¢×™×œ×™×:</b>\n"
                from html import escape as html_escape
                for i, user in enumerate(weekly_users[:15], 1):
                    username = user.get('username') or 'User'
                    # ×”×™××œ×˜×•×ª ×‘×˜×•×—×”
                    safe_username = html_escape(username)
                    if safe_username and safe_username != 'User' and not safe_username.startswith('User_'):
                        # ×”×•×¡×¤×ª @ ×× ×–×” ×©× ××©×ª××© ×˜×œ×’×¨×
                        display_name = f"@{safe_username}" if not safe_username.startswith('@') else safe_username
                    else:
                        display_name = safe_username
                    message += f"{i}. {display_name} - {user['days']} ×™××™× ({user['total_actions']} ×¤×¢×•×œ×•×ª)\n"
                
                if len(weekly_users) > 15:
                    message += f"\n... ×•×¢×•×“ {len(weekly_users) - 15} ××©×ª××©×™×"
            else:
                message += "××™×Ÿ ××©×ª××©×™× ×¤×¢×™×œ×™× ×‘×©×‘×•×¢ ×”××—×¨×•×Ÿ"
            
            await update.message.reply_text(message, parse_mode=ParseMode.HTML, reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True))
        else:
            # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¨×’×™×œ×•×ª ×œ××©×ª××© ×¨×’×™×œ
            stats = db.get_user_stats(user_id)
            
            if not stats or stats.get('total_files', 0) == 0:
                await update.message.reply_text(
                    "ğŸ“Š ×¢×“×™×™×Ÿ ××™×Ÿ ×œ×š ×§×˜×¢×™ ×§×•×“ ×©××•×¨×™×.\n"
                    "×”×ª×—×œ ×¢× /save!",
                    reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
                )
                return
            
            languages_str = ", ".join(stats.get('languages', []))
            last_activity = stats.get('latest_activity')
            last_activity_str = last_activity.strftime('%d/%m/%Y %H:%M') if last_activity else "×œ× ×™×“×•×¢"
            
            response = (
                "ğŸ“Š <b>×”×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×œ×š:</b>\n\n"
                f"ğŸ“ ×¡×”\"×› ×§×‘×¦×™×: <b>{stats['total_files']}</b>\n"
                f"ğŸ”¢ ×¡×”\"×› ×’×¨×¡××•×ª: <b>{stats['total_versions']}</b>\n"
                f"ğŸ’¾ ××’×‘×œ×ª ×§×‘×¦×™×: {config.MAX_FILES_PER_USER}\n\n"
                "ğŸ”¤ <b>×©×¤×•×ª ×‘×©×™××•×©:</b>\n"
                f"{languages_str}\n\n"
                "ğŸ“… <b>×¤×¢×™×œ×•×ª ××—×¨×•× ×”:</b>\n"
                f"{last_activity_str}\n\n"
                "ğŸ’¡ <b>×˜×™×¤:</b> ×”×©×ª××© ×‘×ª×’×™×•×ª ×œ××¨×’×•×Ÿ ×˜×•×‘ ×™×•×ª×¨!"
            )
            
            await update.message.reply_text(response, parse_mode=ParseMode.HTML, reply_markup=ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True))
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×§×‘×¦×™× ×©× ×©×œ×—×™× ×œ×‘×•×˜"""
        
        # ×“×™×‘××’
        logger.info(f"DEBUG: upload_mode = {context.user_data.get('upload_mode')}")
        logger.info(f"DEBUG: waiting_for_github_upload = {context.user_data.get('waiting_for_github_upload')}")
        
        # ×©×—×–×•×¨ ZIP ×™×©×™×¨×•×ª ×œ×¨×™×¤×• ×‘×’×™×˜×”××‘ (×¤×¨×™×¡×” ×•×”×—×œ×¤×”)
        if context.user_data.get('upload_mode') == 'github_restore_zip_to_repo':
            try:
                document = update.message.document
                user_id = update.effective_user.id
                logger.info(f"GitHub restore-to-repo ZIP received: file_name={document.file_name}, size={document.file_size}")
                await update.message.reply_text("â³ ××•×¨×™×“ ×§×•×‘×¥ ZIP...")
                file = await context.bot.get_file(document.file_id)
                buf = BytesIO()
                await file.download_to_memory(buf)
                buf.seek(0)
                import zipfile
                if not zipfile.is_zipfile(buf):
                    await update.message.reply_text("âŒ ×”×§×•×‘×¥ ×©×”×•×¢×œ×” ××™× ×• ZIP ×ª×§×™×Ÿ.")
                    return
                # ×—×œ×¥ ××ª ×”-ZIP ×œ×–×™×›×¨×•×Ÿ ×œ×¨×©×™××ª ×§×‘×¦×™×
                zf = zipfile.ZipFile(buf, 'r')
                # ×¡×™× ×•×Ÿ ×¢×¨×›×™ ××¢×¨×›×ª ×©×œ macOS ×•×›×“'. × ×©××•×¨ ×¨×§ ×§×‘×¦×™× ×××™×ª×™×™×
                all_names = [n for n in zf.namelist() if not n.endswith('/')]
                members = [n for n in all_names if not (n.startswith('__MACOSX/') or n.split('/')[-1].startswith('._'))]
                # ×–×™×”×•×™ ×ª×™×§×™×™×ª-×©×•×¨×© ××©×•×ª×¤×ª (×× ×›×œ ×”×§×‘×¦×™× ×—×•×œ×§×™× ××ª ××•×ª×• ×”×¡×’×× ×˜ ×”×¢×œ×™×•×Ÿ)
                top_levels = set()
                for n in zf.namelist():
                    if '/' in n and not n.startswith('__MACOSX/'):
                        top_levels.add(n.split('/', 1)[0])
                common_root = list(top_levels)[0] if len(top_levels) == 1 else None
                logger.info(f"[restore_zip] Detected common_root={common_root!r}, files_in_zip={len(members)}")
                # × ×§×” ×ª×™×§×™×™×ª root ×©×œ GitHub zip ×¨×§ ×× ×–×•×”×ª×” ×ª×™×§×™×™×ª-×©×•×¨×© ××©×•×ª×¤×ª ××—×ª
                def strip_root(path: str) -> str:
                    if common_root and path.startswith(common_root + '/'):
                        return path[len(common_root) + 1:]
                    return path
                files = []
                for name in members:
                    raw = zf.read(name)
                    clean = strip_root(name)
                    if not clean:
                        continue
                    files.append((clean, raw))
                if not files:
                    await update.message.reply_text("âŒ ×œ× × ××¦××• ×§×‘×¦×™× ×‘×ª×•×š ×”-ZIP")
                    return
                # ×”×¢×œ××” ×œ×’×™×˜×”××‘ ×‘×××¦×¢×•×ª Trees API ×œ×¢×“×›×•×Ÿ ××¨×•×‘×” ×§×‘×¦×™×
                from github import Github
                from github.InputGitTreeElement import InputGitTreeElement
                github_handler = context.bot_data.get('github_handler')
                session = github_handler.get_user_session(user_id)
                token = github_handler.get_user_token(user_id)
                repo_full = session.get('selected_repo')
                if not (token and repo_full):
                    await update.message.reply_text("âŒ ××™×Ÿ ×˜×•×§×Ÿ ××• ×¨×™×¤×• × ×‘×—×¨")
                    return
                # ×™×¢×“ × ×¢×•×œ ×œ×‘×˜×™×—×•×ª: ×× × ×§×‘×¢ ×‘×ª×—×™×œ×ª ×”×–×¨×™××”, ×ª××™×“ × ×¢×“×™×£ ××•×ª×•
                expected_repo_full = context.user_data.get('zip_restore_expected_repo_full')
                repo_full_effective = expected_repo_full or repo_full
                if expected_repo_full and expected_repo_full != repo_full:
                    # ×“×•×•×— ×¢×œ ×¡×˜×™×™×” ××‘×œ ×”××©×š ×‘×‘×˜×—×” ×¢× ×”×™×¢×“ ×”× ×¢×•×œ
                    logger.warning(f"[restore_zip] Target mismatch: expected={expected_repo_full}, got={repo_full}. Proceeding with expected (locked) target.")
                    try:
                        await update.message.reply_text(
                            f"âš ï¸ × ××¦× ×¤×¢×¨ ×‘×™×Ÿ ×”×™×¢×“ ×”× ×•×›×—×™ ({repo_full}) ×œ×™×¢×“ ×”× ×¢×•×œ. × ×©×ª××© ×‘×™×¢×“ ×”× ×¢×•×œ: {expected_repo_full}")
                    except Exception:
                        pass
                # ×× ×œ× × ×©××¨ ×™×¢×“ ×¦×¤×•×™ (×’×¨×¡×” ×™×©× ×”), ×§×‘×¢ ××•×ª×• ×›×¢×ª
                if not expected_repo_full:
                    try:
                        context.user_data['zip_restore_expected_repo_full'] = repo_full
                    except Exception:
                        pass
                g = Github(token)
                # × ×¡×™×•×Ÿ ×’×™×©×” ×œ×™×¢×“ ×”× ×¢×•×œ/×”××¤×§×˜×™×‘×™ ×¢× × ×¤×™×œ×” ×‘×˜×•×—×”
                try:
                    repo = g.get_repo(repo_full_effective)
                except Exception as e:
                    logger.exception(f"[restore_zip] Locked target not accessible: {repo_full_effective}: {e}")
                    # × ×¤×™×œ×” ×‘×˜×•×—×”: ×× ××•×ª×• ×‘×¢×œ×™× ×•×”×¨×™×¤×• ×”× ×•×›×—×™ ×©×•× ×” â€“ × ×¡×” ××ª ×”×¨×™×¤×• ×”× ×•×›×—×™
                    fallback_used = False
                    if repo_full and repo_full != repo_full_effective:
                        try:
                            expected_owner = (expected_repo_full or repo_full_effective).split('/')[0]
                            current_owner = repo_full.split('/')[0]
                        except Exception:
                            expected_owner = None
                            current_owner = None
                        if expected_owner and current_owner and current_owner == expected_owner:
                            try:
                                await update.message.reply_text(
                                    f"âš ï¸ ×”×™×¢×“ ×”× ×¢×•×œ {repo_full_effective} ×œ× × ×’×™×©. ×× ×¡×” ×œ×”×©×ª××© ×‘×™×¢×“ ×”× ×•×›×—×™ {repo_full} (××•×ª×• ×‘×¢×œ×™×).")
                            except Exception:
                                pass
                            try:
                                repo = g.get_repo(repo_full)
                                repo_full_effective = repo_full
                                fallback_used = True
                            except Exception as e2:
                                logger.exception(f"[restore_zip] Fallback to current repo failed: {e2}")
                    if 'repo' not in locals():
                        await update.message.reply_text(
                            f"âŒ ×”×™×¢×“ {repo_full_effective} ×œ× × ×’×™×© ×•××™×Ÿ × ×¤×™×œ×” ×‘×˜×•×—×”. ×¢×¦×™×¨×”. ×× × ×‘×—×¨×• ×¨×™×¤×• ××—×“×©.")
                        raise
                target_branch = repo.default_branch or 'main'
                purge_first = bool(context.user_data.get('github_restore_zip_purge'))
                await update.message.reply_text(
                    ("ğŸ§¹ ×× ×§×” ×§×‘×¦×™× ×§×™×™××™×...\n" if purge_first else "") +
                    f"ğŸ“¤ ××¢×œ×” {len(files)} ×§×‘×¦×™× ×œ×¨×™×¤×• {repo_full_effective} (branch: {target_branch})..."
                )
                # ×‘×¡×™×¡ ×œ×¢×¥
                base_ref = repo.get_git_ref(f"heads/{target_branch}")
                base_commit = repo.get_git_commit(base_ref.object.sha)
                base_tree = base_commit.tree
                new_tree_elements = []
                # ×‘× ×” ×¢×¦×™ ×§×œ×˜
                for path, raw in files:
                    # ×©××•×¨ ×¢×œ ×§×™×“×•×“ × ×›×•×Ÿ: ×˜×§×¡×˜ ×›-utf-8, ×‘×™× ××¨×™ ×›-base64
                    import base64
                    text_exts = ('.md', '.txt', '.json', '.yml', '.yaml', '.xml', '.py', '.js', '.ts', '.tsx', '.css', '.scss', '.html', '.sh', '.gitignore')
                    is_text = path.lower().endswith(text_exts)
                    try:
                        if is_text:
                            text = raw.decode('utf-8')
                            blob = repo.create_git_blob(text, 'utf-8')
                        else:
                            b64 = base64.b64encode(raw).decode('ascii')
                            blob = repo.create_git_blob(b64, 'base64')
                    except Exception:
                        # × ×¤×™×œ×” ×œ×‘×™× ××¨×™ ×× ×›×©×œ ×¤×¢× ×•×—
                        b64 = base64.b64encode(raw).decode('ascii')
                        blob = repo.create_git_blob(b64, 'base64')
                    elem = InputGitTreeElement(path=path, mode='100644', type='blob', sha=blob.sha)
                    new_tree_elements.append(elem)
                if purge_first:
                    # Soft purge: ×™×¦×™×¨×ª ×¢×¥ ×—×“×© ×œ×œ× ×‘×¡×™×¡ (××•×—×§ ×§×‘×¦×™× ×©××™× × ×‘-ZIP)
                    new_tree = repo.create_git_tree(new_tree_elements)
                else:
                    new_tree = repo.create_git_tree(new_tree_elements, base_tree)
                commit_message = f"Restore from ZIP via bot: replace {'with purge' if purge_first else 'update only'}"
                new_commit = repo.create_git_commit(commit_message, new_tree, [base_commit])
                base_ref.edit(new_commit.sha)
                logger.info(f"[restore_zip] Restore commit created: {new_commit.sha}, files_added={len(new_tree_elements)}, purge={purge_first}")
                await update.message.reply_text("âœ… ×”×©×—×–×•×¨ ×”×•×¢×œ×” ×œ×¨×™×¤×• ×‘×”×¦×œ×—×”")
            except Exception as e:
                logger.exception(f"GitHub restore-to-repo failed: {e}")
                await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ ×œ×¨×™×¤×•: {e}")
                # ×”×ª×¨××ª OOM ×œ××“××™×Ÿ ×× ××–×•×”×” ×—×¨×™×’×ª ×–×™×›×¨×•×Ÿ
                try:
                    msg = str(e)
                    if isinstance(e, MemoryError) or 'Ran out of memory' in msg or 'out of memory' in msg.lower():
                        await notify_admins(context, f"ğŸš¨ OOM ×‘×©×—×–×•×¨ ZIP ×œ×¨×™×¤×•: {msg}")
                except Exception:
                    pass
            finally:
                context.user_data['upload_mode'] = None
                context.user_data.pop('github_restore_zip_purge', None)
                try:
                    context.user_data.pop('zip_restore_expected_repo_full', None)
                except Exception:
                    pass
            return
        
        # ×™×¦×™×¨×ª ×¨×™×¤×• ×—×“×© ×â€‘ZIP (×¤×¨×™×¡×” ×œ×ª×•×š ×¨×™×¤×• ×—×“×©)
        if context.user_data.get('upload_mode') == 'github_create_repo_from_zip':
            try:
                document = update.message.document
                user_id = update.effective_user.id
                logger.info(f"GitHub create-repo-from-zip received: file_name={document.file_name}, size={document.file_size}")
                await update.message.reply_text("â³ ××•×¨×™×“ ×§×•×‘×¥ ZIP...")
                tg_file = await context.bot.get_file(document.file_id)
                buf = BytesIO()
                await tg_file.download_to_memory(buf)
                buf.seek(0)
                import zipfile, re, os
                if not zipfile.is_zipfile(buf):
                    await update.message.reply_text("âŒ ×”×§×•×‘×¥ ×©×”×•×¢×œ×” ××™× ×• ZIP ×ª×§×™×Ÿ.")
                    return
                # ×—×œ×¥ ×©××•×ª ×•×‘×—×¨ ×©× ×‘×¡×™×¡ ×œ×¨×™×¤×• ×× ×œ× ×”×•×–×Ÿ ××¨××©
                with zipfile.ZipFile(buf, 'r') as zf:
                    names_all = zf.namelist()
                    file_names = [n for n in names_all if not n.endswith('/') and not n.startswith('__MACOSX/') and not n.split('/')[-1].startswith('._')]
                    if not file_names:
                        await update.message.reply_text("âŒ ×”â€‘ZIP ×¨×™×§." )
                        return
                    # ×’×œ×” root ××©×•×ª×£ ×× ×§×™×™×
                    top_levels = set()
                    for n in names_all:
                        if '/' in n and not n.startswith('__MACOSX/'):
                            top_levels.add(n.split('/', 1)[0])
                    common_root = list(top_levels)[0] if len(top_levels) == 1 else None
                # ×§×‘×¢ ×©× ×¨×™×¤×•
                repo_name = context.user_data.get('new_repo_name')
                if not repo_name:
                    base_guess = None
                    if common_root:
                        base_guess = common_root
                    elif document.file_name:
                        base_guess = os.path.splitext(os.path.basename(document.file_name))[0]
                    if not base_guess:
                        base_guess = f"repo-{int(time.time())}"
                    # sanitize
                    repo_name = re.sub(r"\s+", "-", base_guess)
                    repo_name = re.sub(r"[^A-Za-z0-9._-]", "-", repo_name).strip(".-_") or f"repo-{int(time.time())}"
                # ×”×ª×—×‘×¨ ×œâ€‘GitHub ×•×¦×•×¨ ×¨×™×¤×•
                github_handler = context.bot_data.get('github_handler')
                token = github_handler.get_user_token(user_id) if github_handler else None
                if not token:
                    await update.message.reply_text("âŒ ××™×Ÿ ×˜×•×§×Ÿ GitHub. ×©×œ×— /github ×›×“×™ ×œ×”×ª×—×‘×¨.")
                    return
                await update.message.reply_text(f"ğŸ“¦ ×™×•×¦×¨ ×¨×™×¤×• ×—×“×©: <code>{repo_name}</code>", parse_mode=ParseMode.HTML)
                from github import Github
                g = Github(token)
                user = g.get_user()
                repo = user.create_repo(
                    name=repo_name,
                    private=bool(context.user_data.get('new_repo_private', True)),
                    auto_init=False
                )
                repo_full = repo.full_name
                # ×©××•×¨ ×›×¨×™×¤×• × ×‘×—×¨ ×‘××¡×“ ×•×‘×¡×©×Ÿ
                try:
                    db.save_selected_repo(user_id, repo_full)
                    sess = github_handler.get_user_session(user_id)
                    sess['selected_repo'] = repo_full
                except Exception as e:
                    logger.warning(f"Failed saving selected repo: {e}")
                # ×›×¢×ª ×¤×¨×•×¡ ××ª ×”â€‘ZIP ×œ×¨×™×¤×• ×”×—×“×© ×‘â€‘commit ××—×“
                await update.message.reply_text("ğŸ“¤ ××¢×œ×” ××ª ×§×‘×¦×™ ×”â€‘ZIP ×œ×¨×™×¤×• ×”×—×“×©...")
                # ×§×¨× ×©×•×‘ ××ª ×”â€‘ZIP (×”â€‘buf ×”×•×–×– ×§×“×™××”)
                buf.seek(0)
                with zipfile.ZipFile(buf, 'r') as zf:
                    names_all = zf.namelist()
                    members = [n for n in names_all if not n.endswith('/') and not n.startswith('__MACOSX/') and not n.split('/')[-1].startswith('._')]
                    top_levels = set()
                    for n in names_all:
                        if '/' in n and not n.startswith('__MACOSX/'):
                            top_levels.add(n.split('/', 1)[0])
                    common_root = list(top_levels)[0] if len(top_levels) == 1 else None
                    def strip_root(path: str) -> str:
                        if common_root and path.startswith(common_root + '/'): return path[len(common_root)+1:]
                        return path
                    files = []
                    for name in members:
                        data = zf.read(name)
                        clean = strip_root(name)
                        if clean:
                            files.append((clean, data))
                # ×”×¢×œ××”: ×× ×”×¨×™×¤×• ×¨×™×§ ×œ×—×œ×•×˜×™×Ÿ, Git Data API ×¢×œ×•×œ ×œ×”×—×–×™×¨ 409. ×‘××§×¨×” ×›×–×” × ×©×ª××© ×‘â€‘Contents API ×œ×”×¢×œ××” ×§×•×‘×¥â€‘×§×•×‘×¥.
                from github.GithubException import GithubException
                target_branch = (repo.default_branch or 'main')
                base_ref = None
                base_commit = None
                base_tree = None
                try:
                    base_ref = repo.get_git_ref(f"heads/{target_branch}")
                    base_commit = repo.get_git_commit(base_ref.object.sha)
                    base_tree = base_commit.tree
                except GithubException as _e:
                    logger.info(f"No base ref found for new repo (expected for empty repo): {str(_e)}")

                if base_commit is None:
                    # ×¨×™×¤×• ×¨×™×§: × ×¢×œ×” ×§×‘×¦×™× ×‘×××¦×¢×•×ª Contents API (commit ×œ×›×œ ×§×•×‘×¥)
                    created_count = 0
                    for path, raw in files:
                        try:
                            try:
                                text = raw.decode('utf-8')
                                repo.create_file(path=path, message="Initial import from ZIP via bot", content=text, branch=target_branch)
                            except UnicodeDecodeError:
                                # ×ª×•×›×Ÿ ×‘×™× ××¨×™ â€“ ×©×œ×— ×›-bytes; PyGithub ×™×“××’ ×œ×§×™×“×•×“ Base64
                                repo.create_file(path=path, message="Initial import from ZIP via bot (binary)", content=raw, branch=target_branch)
                            created_count += 1
                        except Exception as e_file:
                            logger.warning(
                                f"[create_repo_from_zip] Failed to create file {path}: {e_file}"
                            )
                    await update.message.reply_text(
                        f"âœ… × ×•×¦×¨ ×¨×™×¤×• ×—×“×© ×•×”×•×–× ×• {created_count} ×§×‘×¦×™×\nğŸ”— <a href=\"https://github.com/{repo_full}\">{repo_full}</a>",
                        parse_mode=ParseMode.HTML
                    )
                    return

                # ××—×¨×ª: ×™×© commit ×‘×¡×™×¡ â€“ × ×©×ª××© ×‘â€‘Git Trees API ×œ×‘×™×¦×•×¢ commit ××¨×•×›×– ××—×“
                from github.InputGitTreeElement import InputGitTreeElement
                import base64
                text_exts = ('.md', '.txt', '.json', '.yml', '.yaml', '.xml', '.py', '.js', '.ts', '.tsx', '.css', '.scss', '.html', '.sh', '.gitignore')
                new_tree_elems = []
                for path, raw in files:
                    try:
                        if path.lower().endswith(text_exts):
                            blob = repo.create_git_blob(raw.decode('utf-8'), 'utf-8')
                        else:
                            blob = repo.create_git_blob(base64.b64encode(raw).decode('ascii'), 'base64')
                    except Exception:
                        blob = repo.create_git_blob(base64.b64encode(raw).decode('ascii'), 'base64')
                    new_tree_elems.append(InputGitTreeElement(path=path, mode='100644', type='blob', sha=blob.sha))
                new_tree = repo.create_git_tree(new_tree_elems, base_tree)
                commit_message = "Initial import from ZIP via bot"
                parents = [base_commit]
                new_commit = repo.create_git_commit(commit_message, new_tree, parents)
                base_ref.edit(new_commit.sha)
                await update.message.reply_text(
                    f"âœ… × ×•×¦×¨ ×¨×™×¤×• ×—×“×© ×•×”×•×–× ×• {len(new_tree_elems)} ×§×‘×¦×™×\nğŸ”— <a href=\"https://github.com/{repo_full}\">{repo_full}</a>",
                    parse_mode=ParseMode.HTML
                )
            except Exception as e:
                logger.exception(f"Create new repo from ZIP failed: {e}")
                await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×¨×™×¤×• ×â€‘ZIP: {e}")
                # ×”×ª×¨××ª OOM ×œ××“××™×Ÿ ×× ××–×•×”×” ×—×¨×™×’×ª ×–×™×›×¨×•×Ÿ
                try:
                    msg = str(e)
                    if isinstance(e, MemoryError) or 'Ran out of memory' in msg or 'out of memory' in msg.lower():
                        await notify_admins(context, f"ğŸš¨ OOM ×‘×™×¦×™×¨×ª ×¨×™×¤×• ×â€‘ZIP: {msg}")
                except Exception:
                    pass
            finally:
                # × ×§×” ×“×’×œ×™ ×–×¨×™××”
                context.user_data['upload_mode'] = None
                for k in ('new_repo_name', 'new_repo_private'):
                    context.user_data.pop(k, None)
            return
        
        # ×‘×“×•×§ ×× ×× ×—× ×• ×‘××¦×‘ ×”×¢×œ××” ×œ×’×™×˜×”××‘ (×ª××™×›×” ×‘×©× ×™ ×”××©×ª× ×™×)
        if context.user_data.get('waiting_for_github_upload') or context.user_data.get('upload_mode') == 'github':
            # × ×”×œ ××ª ×”×”×¢×œ××” ×™×©×™×¨×•×ª ×“×¨×š ×× ×”×œ GitHub ×›×“×™ ×œ× ×œ××‘×“ ××ª ×”××™×¨×•×¢
            github_handler = context.bot_data.get('github_handler')
            if github_handler:
                await github_handler.handle_file_upload(update, context)
            return
        
        # ×™×™×‘×•× ZIP ×¨××©×•× ×™ (×œ×œ× ××—×™×§×”): ×§×‘×œ×ª ZIP ×•×©××™×¨×” ×›×§×‘×¦×™× ×¢× ×ª×’×™×ª ×¨×™×¤×• ×× ×§×™×™××ª
        if context.user_data.get('upload_mode') == 'zip_import':
            try:
                document = update.message.document
                user_id = update.effective_user.id
                logger.info(f"ZIP import received: file_name={document.file_name}, mime_type={document.mime_type}, size={document.file_size}")
                await update.message.reply_text("â³ ××•×¨×™×“ ×§×•×‘×¥ ZIP...")
                file = await context.bot.get_file(document.file_id)
                buf = BytesIO()
                await file.download_to_memory(buf)
                buf.seek(0)
                # ×©××•×¨ ×–×× ×™×ª ×œ×“×™×¡×§
                import tempfile, os, zipfile
                tmp_dir = tempfile.gettempdir()
                safe_name = (document.file_name or 'repo.zip')
                if not safe_name.lower().endswith('.zip'):
                    safe_name += '.zip'
                tmp_path = os.path.join(tmp_dir, safe_name)
                with open(tmp_path, 'wb') as f:
                    f.write(buf.getvalue())
                # ×‘×“×™×§×ª ZIP ×ª×§×™×Ÿ
                if not zipfile.is_zipfile(tmp_path):
                    logger.warning(f"Uploaded file is not a valid ZIP: {tmp_path}")
                    await update.message.reply_text("âŒ ×”×§×•×‘×¥ ×©×”×•×¢×œ×” ××™× ×• ZIP ×ª×§×™×Ÿ.")
                    return
                # × ×¡×” ×œ×§×¨×•× metadata ×›×“×™ ×œ×¦×¨×£ ×ª×’×™×ª repo
                import json, re
                repo_tag = []
                # 1) × ×¡×” metadata.json ×›×¤×™ ×©××™×•×¦×¨ ×¢"×™ ×–×¨×™××•×ª ×”×‘×•×˜
                try:
                    with zipfile.ZipFile(tmp_path, 'r') as zf:
                        md = json.loads(zf.read('metadata.json'))
                        if md.get('repo'):
                            repo_tag = [f"repo:{md['repo']}"]
                except Exception:
                    repo_tag = []
                # 2) ×× ××™×Ÿ ××˜××“×˜×”: × ×¡×” ×œ×’×œ×•×ª owner/name ××ª×•×š ×ª×™×§×™×™×ª ×”×©×•×¨×© ×©×œ GitHub ZIP ××• ×©× ×”×§×•×‘×¥
                if not repo_tag:
                    try:
                        def _parse_repo_full_from_label(label: str) -> str:
                            if not isinstance(label, str) or not label:
                                return ""
                            # × ×§×” ×¡×™×•××•×ª ×•× ×ª×™×‘×™×
                            base = label.strip().strip('/').strip()
                            base = re.sub(r"\.zip$", "", base, flags=re.IGNORECASE)
                            # ×¤×¢× ×•×— ×ª×‘× ×™×ª GitHub: owner-repo-<branch|sha>
                            parts = base.split('-') if '-' in base else [base]
                            if len(parts) < 2:
                                return ""
                            owner = parts[0]
                            # ×”×¡×¨ ×¡×™×•××•×ª × ×¤×•×¦×•×ª ×©×œ branch/sha
                            tail = parts[1:]
                            while tail:
                                last = tail[-1]
                                is_sha = bool(re.fullmatch(r"[0-9a-fA-F]{7,40}", last))
                                is_branch_hint = last.lower() in {"main", "master", "develop", "dev", "release"}
                                if is_sha or is_branch_hint:
                                    tail = tail[:-1]
                                else:
                                    break
                            if not tail:
                                return ""
                            repo_name = "-".join(tail)
                            if not owner or not repo_name:
                                return ""
                            return f"{owner}/{repo_name}"

                        guessed_full = ""
                        # ××ª×•×š ×ª×™×§×™×™×ª ×”×©×•×¨×© ×©×œ ×”â€‘ZIP (GitHub ×©× ×©× ×™×—×™×“ ×œ×¨×•×‘)
                        with zipfile.ZipFile(tmp_path, 'r') as zf:
                            all_names = zf.namelist()
                            top_levels = set()
                            for n in all_names:
                                if '/' in n and not n.startswith('__MACOSX/'):
                                    top_levels.add(n.split('/', 1)[0])
                            common_root = list(top_levels)[0] if len(top_levels) == 1 else None
                        if common_root:
                            guessed_full = _parse_repo_full_from_label(common_root)
                        if not guessed_full and safe_name:
                            name_wo_ext = os.path.splitext(os.path.basename(safe_name))[0]
                            guessed_full = _parse_repo_full_from_label(name_wo_ext)
                        if guessed_full:
                            repo_tag = [f"repo:{guessed_full}"]
                    except Exception:
                        repo_tag = []
                # ×‘×¦×¢ ×™×™×‘×•× ×œ×œ× ××—×™×§×”, ×¢× ×ª×’×™×•×ª ×× ×§×™×™××•×ª
                results = backup_manager.restore_from_backup(user_id=user_id, backup_path=tmp_path, overwrite=True, purge=False, extra_tags=repo_tag)
                restored = results.get('restored_files', 0)
                errors = results.get('errors', [])
                if errors:
                    # ×”×¦×’ ×ª×§×¦×™×¨ ×©×’×™××•×ª ×›×“×™ ×œ×¢×–×•×¨ ×‘××‘×—×•×Ÿ
                    preview = "\n".join([str(e) for e in errors[:3]])
                    msg = (
                        f"âš ï¸ ×”×™×™×‘×•× ×”×•×©×œ× ×—×œ×§×™×ª: {restored} ×§×‘×¦×™× × ×©××¨×•\n"
                        f"×©×’×™××•×ª: {len(errors)}\n"
                        f"×“×•×’×××•×ª:\n{preview}"
                    )
                else:
                    msg = f"âœ… ×™×•×‘××• {restored} ×§×‘×¦×™× ×‘×”×¦×œ×—×”"
                await update.message.reply_text(msg)
            except Exception as e:
                logger.exception(f"ZIP import failed: {e}")
                await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×™×™×‘×•× ZIP: {e}")
            finally:
                context.user_data['upload_mode'] = None
            return

        # ××¦×‘ ××™×¡×•×£ ×§×‘×¦×™× ×œ×™×¦×™×¨×ª ZIP ××§×•××™
        if context.user_data.get('upload_mode') == 'zip_create':
            try:
                document = update.message.document
                user_id = update.effective_user.id
                logger.info(f"ZIP create mode: received file for bundle: {document.file_name} ({document.file_size} bytes)")
                # ×”×•×¨×“×” ×œ×–×™×›×¨×•×Ÿ
                file = await context.bot.get_file(document.file_id)
                buf = BytesIO()
                await file.download_to_memory(buf)
                raw = buf.getvalue()
                # ×©××™×¨×” ×œ×¨×©×™××ª ×”×¤×¨×™×˜×™× ×‘×¡×©×Ÿ
                items = context.user_data.get('zip_create_items')
                if items is None:
                    items = []
                    context.user_data['zip_create_items'] = items
                # ×§×‘×™×¢×ª ×©× ×‘×˜×•×—
                safe_name = (document.file_name or f"file_{len(items)+1}").strip() or f"file_{len(items)+1}"
                items.append({
                    'filename': safe_name,
                    'bytes': raw,
                })
                await update.message.reply_text(f"âœ… × ×•×¡×£: <code>{html_escape(safe_name)}</code> (×¡×”""×› {len(items)} ×§×‘×¦×™×)", parse_mode=ParseMode.HTML)
            except Exception as e:
                logger.exception(f"zip_create collect failed: {e}")
                await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ×”×§×•×‘×¥ ×œâ€‘ZIP: {e}")
            return
        
        await log_user_activity(update, context)
        
        try:
            document = update.message.document
            user_id = update.effective_user.id
            
            # ×‘×“×™×§×ª ×’×•×“×œ ×”×§×•×‘×¥ (×¢×“ 20MB)
            if document.file_size > 20 * 1024 * 1024:
                await update.message.reply_text(
                    "âŒ ×”×§×•×‘×¥ ×’×“×•×œ ××“×™!\n"
                    "ğŸ“ ×”×’×•×“×œ ×”××§×¡×™××œ×™ ×”××•×ª×¨ ×”×•× 20MB"
                )
                return
            
            # ×”×•×¨×“×ª ×”×§×•×‘×¥
            await update.message.reply_text("â³ ××•×¨×™×“ ××ª ×”×§×•×‘×¥...")
            file = await context.bot.get_file(document.file_id)
            
            # ×§×¨×™××ª ×”×ª×•×›×Ÿ
            file_bytes = BytesIO()
            await file.download_to_memory(file_bytes)
            file_bytes.seek(0)
            
            # × ×™×¡×™×•×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥ ×‘×§×™×“×•×“×™× ×©×•× ×™×
            content = None
            detected_encoding = None
            encodings_to_try = ['utf-8', 'windows-1255', 'iso-8859-8', 'cp1255', 'utf-16', 'latin-1']
            
            # ×œ×•×’ ×¤×¨×˜×™ ×”×§×•×‘×¥
            logger.info(f"ğŸ“„ ×§×•×‘×¥ × ×©×œ×—: {document.file_name}, ×’×•×“×œ: {document.file_size} bytes")
            
            # ×§×¨× ××ª ×”×‘×™×™×˜×™×
            raw_bytes = file_bytes.read()
            file_size_bytes = len(raw_bytes)
            
            # ×× ×”×§×•×‘×¥ ×”×•× ZIP (×’× ×× ×”×•×¢×œ×” "×¡×ª×" ×‘××¡×œ×•×œ ×§×‘×¦×™×), × ×©××•×¨ ×¢×•×ª×§ ×œ×ª×™×§×™×™×ª ×”-ZIP ×”×©××•×¨×™×
            try:
                import zipfile as _zip
                from io import BytesIO as _BytesIO
                is_zip_hint = ((document.mime_type or '').lower() == 'application/zip') or ((document.file_name or '').lower().endswith('.zip'))
                is_zip_actual = False
                try:
                    is_zip_actual = _zip.is_zipfile(_BytesIO(raw_bytes))
                except Exception:
                    is_zip_actual = False
                if is_zip_hint and is_zip_actual:
                    backup_id = f"upload_{user_id}_{int(datetime.now(timezone.utc).timestamp())}"
                    target_path = backup_manager.backup_dir / f"{backup_id}.zip"
                    try:
                        # ×”×•×¡×£ metadata.json ×‘×¡×™×¡×™ (×× ×—×¡×¨) ×•×©××•×¨ ×‘×”×ª×× ×œ××—×¡×•×Ÿ (Mongo/FS)
                        try:
                            # × ×¡×” ×œ×¤×ª×•×— ××ª ×”-ZIP ×”××§×•×¨×™ ×›×“×™ ×œ×‘×“×•×§ ××˜××“×˜×”
                            ztest = _zip.ZipFile(_BytesIO(raw_bytes))
                            try:
                                ztest.getinfo('metadata.json')
                                # ×›×‘×¨ ×§×™×™× metadata.json â€“ × ×©××•×¨ ×›××• ×©×”×•×
                                md_bytes = raw_bytes
                            except KeyError:
                                # ×”×–×¨×§×ª ××˜××“×˜×”
                                md = {
                                    "backup_id": backup_id,
                                    "backup_type": "generic_zip",
                                    "user_id": user_id,
                                    "created_at": datetime.now(timezone.utc).isoformat(),
                                    "original_filename": document.file_name,
                                    "source": "uploaded_document"
                                }
                                out_buf = _BytesIO()
                                with _zip.ZipFile(out_buf, 'w', compression=_zip.ZIP_DEFLATED) as zout:
                                    # ×”×¢×ª×§ ××ª ×”×ª×•×›×Ÿ
                                    for name in ztest.namelist():
                                        zout.writestr(name, ztest.read(name))
                                    zout.writestr('metadata.json', json.dumps(md, indent=2))
                                md_bytes = out_buf.getvalue()
                        except Exception:
                            # ×× ×œ× ××¦×œ×™×—×™× ×œ×§×¨×•× ×›-ZIP, × ×©××•×¨ ××ª ×”×‘×™×™×˜×™× ×”××§×•×¨×™×™×
                            md_bytes = raw_bytes

                        # ×©××™×¨×” ×œ×¤×™ ××¦×‘ ×”××—×¡×•×Ÿ
                        try:
                            backup_manager.save_backup_bytes(md_bytes, {"backup_id": backup_id, "backup_type": "generic_zip", "user_id": user_id, "created_at": datetime.now(timezone.utc).isoformat(), "original_filename": document.file_name, "source": "uploaded_document"})
                        except Exception:
                            # × ×¤×™×œ×” ×œ×©××™×¨×” ×œ×“×™×¡×§ ×›× ×™×¡×™×•×Ÿ ××—×¨×•×Ÿ
                            with open(target_path, 'wb') as fzip:
                                fzip.write(md_bytes)
                        await update.message.reply_text(
                            "âœ… ×§×•×‘×¥ ZIP × ×©××¨ ×‘×”×¦×œ×—×” ×œ×¨×©×™××ª ×”â€‘ZIP ×”×©××•×¨×™×.\n"
                            "ğŸ“¦ × ×™×ª×Ÿ ×œ××¦×•× ××•×ª×• ×ª×—×ª: 'ğŸ“š' > 'ğŸ“¦ ×§×‘×¦×™ ZIP' ××• ×‘â€‘Batch/GitHub.")
                        return
                    except Exception as e:
                        logger.warning(f"Failed to persist uploaded ZIP: {e}")
                        # ×”××©×š ×œ×–×¨×™××ª ×§×¨×™××ª ×˜×§×¡×˜ ×”×¨×’×™×œ×”
            except Exception:
                pass

            # × ×¡×” ×§×™×“×•×“×™× ×©×•× ×™×
            for encoding in encodings_to_try:
                try:
                    content = raw_bytes.decode(encoding)
                    detected_encoding = encoding
                    logger.info(f"âœ… ×”×§×•×‘×¥ × ×§×¨× ×‘×”×¦×œ×—×” ×‘×§×™×“×•×“: {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
            
            if content is None:
                logger.error(f"âŒ ×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥ ×‘××£ ×§×™×“×•×“: {encodings_to_try}")
                await update.message.reply_text(
                    "âŒ ×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥!\n"
                    f"ğŸ“ × ×™×¡×™×ª×™ ××ª ×”×§×™×“×•×“×™×: {', '.join(encodings_to_try)}\n"
                    "ğŸ’¡ ×× × ×•×“× ×©×–×”×• ×§×•×‘×¥ ×˜×§×¡×˜/×§×•×“ ×•×œ× ×§×•×‘×¥ ×‘×™× ××¨×™"
                )
                return
            
            # ×–×™×”×•×™ ×©×¤×ª ×ª×›× ×•×ª
            file_name = document.file_name or "untitled.txt"
            from utils import detect_language_from_filename
            language = detect_language_from_filename(file_name)
            
            # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×’×“×•×œ (××¢×œ 4096 ×ª×•×•×™×)
            if len(content) > 4096:
                # ×©××™×¨×” ×›×§×•×‘×¥ ×’×“×•×œ
                from database import LargeFile
                large_file = LargeFile(
                    user_id=user_id,
                    file_name=file_name,
                    content=content,
                    programming_language=language,
                    file_size=len(content.encode('utf-8')),
                    lines_count=len(content.split('\n'))
                )
                
                success = db.save_large_file(large_file)
                
                if success:
                    from utils import get_language_emoji
                    emoji = get_language_emoji(language)
                    
                    # ×©×œ×•×£ ××ª ×”-ObjectId ×”××—×¨×•×Ÿ ×©×œ ×”×§×•×‘×¥ ×”×’×“×•×œ ×›×“×™ ×œ××¤×©×¨ ×©×™×ª×•×£
                    try:
                        from bson import ObjectId
                        # × ×¡×” ×œ××—×–×¨ ×œ×¤×™ ×©× â€” ×”×¤×•× ×§×¦×™×” ×©×œ ×”-repo ×œ×§×‘×¦×™× ×’×“×•×œ×™× ×§×™×™××ª
                        saved_large = db.get_large_file(user_id, file_name) or {}
                        fid = str(saved_large.get('_id') or '')
                    except Exception:
                        fid = ''
                    keyboard = [
                        [InlineKeyboardButton("ğŸ‘ï¸ ×”×¦×’ ×§×•×“", callback_data=f"view_direct_id:{fid}" if fid else f"view_direct_{file_name}"), InlineKeyboardButton("ğŸ“š ×”×¦×’ ×§×‘×¦×™× ×’×“×•×œ×™×", callback_data="show_large_files")],
                        [InlineKeyboardButton("ğŸ”— ×©×ª×£ ×§×•×“", callback_data=f"share_menu_id:{fid}") if fid else InlineKeyboardButton("ğŸ”— ×©×ª×£ ×§×•×“", callback_data=f"share_menu_id:")],
                        [InlineKeyboardButton("ğŸ  ×ª×¤×¨×™×˜ ×¨××©×™", callback_data="main")]
                    ]
                    reply_markup = InlineKeyboardMarkup(keyboard)
                    
                    lines_count = len(content.split('\n'))
                    await update.message.reply_text(
                        f"âœ… **×”×§×•×‘×¥ × ×©××¨ ×‘×”×¦×œ×—×”!**\n\n"
                        f"ğŸ“„ **×©×:** `{file_name}`\n"
                        f"{emoji} **×©×¤×”:** {language}\n"
                        f"ğŸ”¤ **×§×™×“×•×“:** {detected_encoding}\n"
                        f"ğŸ’¾ **×’×•×“×œ:** {len(content):,} ×ª×•×•×™×\n"
                        f"ğŸ“ **×©×•×¨×•×ª:** {lines_count:,}\n\n"
                        f"ğŸ® ×‘×—×¨ ×¤×¢×•×œ×” ××”×›×¤×ª×•×¨×™× ×”×—×›××™×:",
                        reply_markup=reply_markup,
                        parse_mode='Markdown'
                    )
                    try:
                        context.user_data['last_save_success'] = {
                            'file_name': file_name,
                            'language': language,
                            'note': '',
                            'file_id': fid,
                        }
                    except Exception:
                        pass
                else:
                    await update.message.reply_text("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×§×•×‘×¥")
            else:
                # ×©××™×¨×” ×›×§×•×‘×¥ ×¨×’×™×œ
                from database import CodeSnippet
                snippet = CodeSnippet(
                    user_id=user_id,
                    file_name=file_name,
                    code=content,
                    programming_language=language
                )
                
                success = db.save_code_snippet(snippet)
                
                if success:
                    from utils import get_language_emoji
                    emoji = get_language_emoji(language)
                    
                    # ×©×œ×•×£ ××ª ×”-ObjectId ×”××—×¨×•×Ÿ ×›×“×™ ×œ××¤×©×¨ ×©×™×ª×•×£
                    try:
                        saved_doc = db.get_latest_version(user_id, file_name) or {}
                        fid = str(saved_doc.get('_id') or '')
                    except Exception:
                        fid = ''
                    keyboard = [
                        [InlineKeyboardButton("ğŸ‘ï¸ ×”×¦×’ ×§×•×“", callback_data=f"view_direct_id:{fid}" if fid else f"view_direct_{file_name}"), InlineKeyboardButton("âœï¸ ×¢×¨×•×š", callback_data=f"edit_code_direct_{file_name}")],
                        [InlineKeyboardButton("ğŸ“¥ ×”×•×¨×“", callback_data=f"download_direct_{file_name}"), InlineKeyboardButton("ğŸ“š ×”×™×¡×˜×•×¨×™×”", callback_data=f"versions_file_{file_name}")],
                        [InlineKeyboardButton("ğŸ”— ×©×ª×£ ×§×•×“", callback_data=f"share_menu_id:{fid}") if fid else InlineKeyboardButton("ğŸ”— ×©×ª×£ ×§×•×“", callback_data=f"share_menu_id:")],
                        [InlineKeyboardButton("ğŸ“š ×”×¦×’ ××ª ×›×œ ×”×§×‘×¦×™×", callback_data="files")],
                        [InlineKeyboardButton("ğŸ  ×ª×¤×¨×™×˜ ×¨××©×™", callback_data="main")]
                    ]
                    reply_markup = InlineKeyboardMarkup(keyboard)
                    
                    await update.message.reply_text(
                        f"âœ… **×”×§×•×‘×¥ × ×©××¨ ×‘×”×¦×œ×—×”!**\n\n"
                        f"ğŸ“„ **×©×:** `{file_name}`\n"
                        f"{emoji} **×©×¤×”:** {language}\n"
                        f"ğŸ”¤ **×§×™×“×•×“:** {detected_encoding}\n"
                        f"ğŸ’¾ **×’×•×“×œ:** {len(content)} ×ª×•×•×™×\n\n"
                        f"ğŸ® ×‘×—×¨ ×¤×¢×•×œ×” ××”×›×¤×ª×•×¨×™× ×”×—×›××™×:",
                        reply_markup=reply_markup,
                        parse_mode='Markdown'
                    )
                    try:
                        context.user_data['last_save_success'] = {
                            'file_name': file_name,
                            'language': language,
                            'note': '',
                            'file_id': fid,
                        }
                    except Exception:
                        pass
                else:
                    await update.message.reply_text("âŒ ×©×’×™××” ×‘×©××™×¨×ª ×”×§×•×‘×¥")
            
            reporter.report_activity(user_id)
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×˜×™×¤×•×œ ×‘×§×•×‘×¥: {e}")
            await update.message.reply_text("âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×§×•×‘×¥")
    
    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×”×•×“×¢×•×ª ×˜×§×¡×˜ (×§×•×“ ×¤×•×˜× ×¦×™××œ×™)"""
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)
        user_id = update.effective_user.id
        text = update.message.text

        # ××¦×‘ ×—×™×¤×•×© ××™× ×˜×¨××§×˜×™×‘×™ (××•×¤×¢×œ ××”×›×¤×ª×•×¨ "ğŸ” ×—×¤×© ×§×•×‘×¥")
        if context.user_data.get('awaiting_search_text'):
            query_text = (text or '').strip()
            context.user_data.pop('awaiting_search_text', None)

            # ×¤×™×¨×•×§ ×©××™×œ×ª×: ×ª×•××š name:..., lang:..., tag:repo:...
            name_substr = []
            lang_filter = None
            tag_filter = None
            try:
                tokens = [t for t in query_text.split() if t.strip()]
                for t in tokens:
                    lower = t.lower()
                    if lower.startswith('name:'):
                        name_substr.append(t.split(':', 1)[1])
                    elif lower.startswith('lang:'):
                        lang_filter = t.split(':', 1)[1].strip().lower() or None
                    elif lower.startswith('tag:'):
                        tag_filter = t.split(':', 1)[1].strip()
                    elif lower.startswith('repo:'):
                        tag_filter = t.strip()
                    else:
                        # ××•× ×—×™ ×—×™×¤×•×© ×—×•×¤×©×™×™× ×‘×©× ×”×§×•×‘×¥
                        name_substr.append(t)
                name_filter = ' '.join(name_substr).strip()
            except Exception:
                name_filter = query_text

            # ××—×–×•×¨ ×ª×•×¦××•×ª
            from database import db
            # × ×—×¤×© ×‘×‘×¡×™×¡ (×›×•×œ×œ $text), ×•××– × ×¡× ×Ÿ ×œ×¤×™ ×©× ×§×•×‘×¥ ×× ×”×•×’×“×¨ name_filter
            results = db.search_code(
                user_id,
                query=name_filter if name_filter else "",
                programming_language=lang_filter,
                tags=[tag_filter] if tag_filter else None,
                limit=10000,
            ) or []
            # ×¡×™× ×•×Ÿ ×œ×¤×™ ×©× ×§×•×‘×¥ ×× ×™×© name_filter
            if name_filter:
                try:
                    nf = name_filter.lower()
                    results = [r for r in results if nf in str(r.get('file_name', '')).lower()]
                except Exception:
                    pass

            total = len(results)
            if total == 0:
                await update.message.reply_text(
                    "ğŸ” ×œ× × ××¦××• ×ª×•×¦××•×ª.",
                    reply_to_message_id=update.message.message_id,
                )
                # ××¤×©×¨ ×œ××¤×©×¨ ×—×™×¤×•×© × ×•×¡×£ ××™×“
                context.user_data['awaiting_search_text'] = True
                return

            # ×©××™×¨×ª ×¤×™×œ×˜×¨×™× ×œ×”××©×š ×“×¤×“×•×£
            context.user_data['search_filters'] = {
                'name_filter': name_filter,
                'lang': lang_filter,
                'tag': tag_filter,
            }
            context.user_data['files_origin'] = { 'type': 'search' }

            # ×‘× ×™×™×ª ×¢××•×“ ×¨××©×•×Ÿ
            PAGE_SIZE = 10
            page = 1
            context.user_data['files_last_page'] = page
            start = (page - 1) * PAGE_SIZE
            end = min(start + PAGE_SIZE, total)

            # ×‘× ×™×™×ª ××§×œ×“×ª ×ª×•×¦××•×ª
            from telegram import InlineKeyboardMarkup, InlineKeyboardButton
            keyboard = []
            context.user_data['files_cache'] = {}
            for i in range(start, end):
                item = results[i]
                fname = item.get('file_name', '×§×•×‘×¥')
                lang = item.get('programming_language', 'text')
                button_text = f"ğŸ“„ {fname} ({lang})"
                keyboard.append([InlineKeyboardButton(button_text, callback_data=f"file_{i}")])
                context.user_data['files_cache'][str(i)] = item

            # ×¢×™××•×“
            total_pages = (total + PAGE_SIZE - 1) // PAGE_SIZE if total > 0 else 1
            row = []
            if page > 1:
                row.append(InlineKeyboardButton("â¬…ï¸ ×”×§×•×“×", callback_data=f"search_page_{page-1}"))
            if page < total_pages:
                row.append(InlineKeyboardButton("â¡ï¸ ×”×‘×", callback_data=f"search_page_{page+1}"))
            if row:
                keyboard.append(row)
            keyboard.append([InlineKeyboardButton("ğŸ”™ ×—×–×¨×”", callback_data="files")])

            await update.message.reply_text(
                f"ğŸ” ×ª×•×¦××•×ª ×—×™×¤×•×© â€” ×¡×”×´×›: {total}\n" +
                f"ğŸ“„ ×¢××•×“ {page} ××ª×•×š {total_pages}",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            return

        # ×‘×™×˜×•×œ ×—×“-×¤×¢××™ ×©×œ ×”×•×“×¢×ª "× ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!" (×œ××©×œ ××—×¨×™ ×©××™×¨×ª ×”×¢×¨×” ×œ×’×™×‘×•×™)
        if context.user_data.pop('suppress_code_hint_once', False):
            return
        
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×‘×ª×”×œ×™×š ×©××™×¨×”
        if 'saving_file' in context.user_data:
            await self._save_code_snippet(update, context, text)
            return
        
        # ×–×™×”×•×™ ×× ×–×” × ×¨××” ×›××• ×§×•×“, ×œ××¢×˜ ×‘×–××Ÿ ×–×¨×™××ª "×”×“×‘×§ ×§×•×“" ×©×œ GitHub
        if self._looks_like_code(text) and not (
            context.user_data.get('waiting_for_paste_content') or context.user_data.get('waiting_for_paste_filename')
        ):
            await update.message.reply_text(
                "ğŸ¤” × ×¨××” ×©×–×” ×§×˜×¢ ×§×•×“!\n"
                "×¨×•×¦×” ×œ×©××•×¨ ××•×ª×•? ×”×©×ª××© ×‘/save ××• ×©×œ×— ×©×•×‘ ×¢× ×©× ×§×•×‘×¥.",
                reply_to_message_id=update.message.message_id
            )
        # ×©×œ×‘ ×‘×™× ×™×™× ×œ×§×œ×™×˜×ª ×”×¢×¨×” ××—×¨×™ ×§×•×“
        elif 'saving_file' in context.user_data and context.user_data['saving_file'].get('note_asked') and 'pending_code_buffer' in context.user_data:
            note_text = (text or '').strip()
            if note_text.lower() in {"×“×œ×’", "skip", "×œ×œ×", ""}:
                context.user_data['saving_file']['note_value'] = ""
            else:
                # ×”×’×‘×œ×ª ××•×¨×š ×”×¢×¨×”
                context.user_data['saving_file']['note_value'] = note_text[:280]
            # ×§×¨× ×©×•×‘ ×œ×©××™×¨×” ×‘×¤×•×¢×œ (×ª×“×œ×’ ×¢×œ ×”×©××œ×” ×›×™ note_asked=true)
            await self._save_code_snippet(update, context, context.user_data.get('pending_code_buffer', ''))
    
    async def _save_code_snippet(self, update: Update, context: ContextTypes.DEFAULT_TYPE, code: str):
        """×©××™×¨×” ×‘×¤×•×¢×œ ×©×œ ×§×˜×¢ ×§×•×“"""
        reporter.report_activity(update.effective_user.id)
        saving_data = context.user_data.pop('saving_file')
        
        if len(code) > config.MAX_CODE_SIZE:
            await update.message.reply_text(
                f"âŒ ×”×§×•×“ ×’×“×•×œ ××“×™! ××§×¡×™××•× {config.MAX_CODE_SIZE} ×ª×•×•×™×."
            )
            return
        
        # ×–×™×”×•×™ ×©×¤×ª ×”×ª×›× ×•×ª ×‘×××¦×¢×•×ª CodeProcessor
        detected_language = code_processor.detect_language(code, saving_data['file_name'])
        logger.info(f"×–×•×”×ª×” ×©×¤×”: {detected_language} ×¢×‘×•×¨ ×”×§×•×‘×¥ {saving_data['file_name']}")
        
        # ×× ×˜×¨× × ×©××¨×” ×”×¢×¨×”, × ×©××œ ×›×¢×ª
        if not saving_data.get('note_asked'):
            saving_data['note_asked'] = True
            context.user_data['saving_file'] = saving_data
            context.user_data['pending_code_buffer'] = code
            await update.message.reply_text(
                "ğŸ“ ×¨×•×¦×” ×œ×”×•×¡×™×£ ×”×¢×¨×” ×§×¦×¨×” ×œ×§×•×‘×¥?\n"
                "×›×ª×•×‘/×›×ª×‘×™ ××•×ª×” ×¢×›×©×™×• ××• ×©×œ×—/×™ '×“×œ×’' ×›×“×™ ×œ×©××•×¨ ×‘×œ×™ ×”×¢×¨×”."
            )
            return

        # ×©×œ×‘ ×©× ×™: ×›×‘×¨ × ×©××œ×” ×”×¢×¨×”, ×‘×“×•×§ ×× ×”×ª×§×‘×œ×”
        note = saving_data.get('note_value') or ""
        if 'pending_code_buffer' in context.user_data:
            code = context.user_data.pop('pending_code_buffer')

        # ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ ×§×˜×¢ ×§×•×“ ×›×•×œ×œ ×”×¢×¨×” (description)
        snippet = CodeSnippet(
            user_id=saving_data['user_id'],
            file_name=saving_data['file_name'],
            code=code,
            programming_language=detected_language,
            description=note,
            tags=saving_data['tags']
        )
        
        # ×©××™×¨×” ×‘××¡×“ ×”× ×ª×•× ×™×
        if db.save_code_snippet(snippet):
            await update.message.reply_text(
                f"âœ… × ×©××¨ ×‘×”×¦×œ×—×”!\n\n"
                f"ğŸ“ **{saving_data['file_name']}**\n"
                f"ğŸ”¤ ×©×¤×”: {detected_language}\n"
                f"ğŸ·ï¸ ×ª×’×™×•×ª: {', '.join(saving_data['tags']) if saving_data['tags'] else '×œ×œ×'}\n"
                f"ğŸ“ ×”×¢×¨×”: {note or 'â€”'}\n"
                f"ğŸ“Š ×’×•×“×œ: {len(code)} ×ª×•×•×™×",
                parse_mode=ParseMode.HTML
            )
        else:
            await update.message.reply_text(
                "âŒ ×©×’×™××” ×‘×©××™×¨×”. × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."
            )
    
    def _looks_like_code(self, text: str) -> bool:
        """×‘×“×™×§×” ×¤×©×•×˜×” ×× ×˜×§×¡×˜ × ×¨××” ×›××• ×§×•×“"""
        code_indicators = [
            'def ', 'function ', 'class ', 'import ', 'from ',
            '){', '};', '<?php', '<html', '<script', 'SELECT ', 'CREATE TABLE'
        ]
        
        return any(indicator in text for indicator in code_indicators) or \
               text.count('\n') > 3 or text.count('{') > 1
    
    def _detect_language(self, filename: str, code: str) -> str:
        """×–×™×”×•×™ ×‘×¡×™×¡×™ ×©×œ ×©×¤×ª ×ª×›× ×•×ª (×™×•×¨×—×‘ ×‘×¢×ª×™×“)"""
        # ×–×™×”×•×™ ×œ×¤×™ ×¡×™×•××ª ×§×•×‘×¥
        extension_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.html': 'html',
            '.css': 'css',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.php': 'php',
            '.rb': 'ruby',
            '.go': 'go',
            '.rs': 'rust',
            '.ts': 'typescript',
            '.sql': 'sql',
            '.sh': 'bash',
            '.json': 'json',
            '.xml': 'xml',
            '.yml': 'yaml',
            '.yaml': 'yaml'
        }
        
        for ext, lang in extension_map.items():
            if filename.lower().endswith(ext):
                return lang
        
        # ×–×™×”×•×™ ×‘×¡×™×¡×™ ×œ×¤×™ ×ª×•×›×Ÿ
        if 'def ' in code or 'import ' in code:
            return 'python'
        elif 'function ' in code or 'var ' in code or 'let ' in code:
            return 'javascript'
        elif '<?php' in code:
            return 'php'
        elif '<html' in code or '<!DOCTYPE' in code:
            return 'html'
        elif 'SELECT ' in code.upper() or 'CREATE TABLE' in code.upper():
            return 'sql'
        
        return 'text'  # ×‘×¨×™×¨×ª ××—×“×œ
    
    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×©×’×™××•×ª"""
        logger.error(f"×©×’×™××”: {context.error}", exc_info=context.error)

        # ×–×™×”×•×™ ×—×¨×™×’×ª ×–×™×›×¨×•×Ÿ (×’×œ×•×‘×œ×™)
        try:
            err = context.error
            err_text = str(err) if err else ""
            is_oom = isinstance(err, MemoryError) or (
                isinstance(err_text, str) and (
                    'Ran out of memory' in err_text or 'out of memory' in err_text.lower() or 'MemoryError' in err_text
                )
            )
            if is_oom:
                # × ×¡×” ×œ×¦×¨×£ ×¡×˜×˜×•×¡ ×–×™×›×¨×•×Ÿ
                mem_status = ""
                try:
                    from utils import get_memory_usage  # import ××§×•××™ ×œ×× ×™×¢×ª ×ª×œ×•×ª ×‘×–××Ÿ ×‘×“×™×§×•×ª
                    mu = get_memory_usage()
                    mem_status = f" (RSS={mu.get('rss_mb')}MB, VMS={mu.get('vms_mb')}MB, %={mu.get('percent')})"
                except Exception:
                    pass
                # ×©×œ×— ×”×ª×¨××” ×œ××“××™× ×™×
                try:
                    await notify_admins(context, f"ğŸš¨ OOM ×–×•×”×ª×” ×‘×‘×•×˜{mem_status}. ×—×¨×™×’×”: {err_text[:500]}")
                except Exception:
                    pass
                # ×× ×”××©×ª××© ××“××™×Ÿ â€“ ×©×œ×— ×’× ××œ×™×• ×¤×™×¨×•×˜
                try:
                    if isinstance(update, Update) and update.effective_user:
                        admin_ids = get_admin_ids()
                        if admin_ids and update.effective_user.id in admin_ids:
                            await context.bot.send_message(chat_id=update.effective_user.id,
                                                           text=f"ğŸš¨ OOM ×–×•×”×ª×”{mem_status}. ×”×ª×§×‘×œ×” ×©×’×™××”: {err_text[:500]}")
                except Exception:
                    pass
        except Exception:
            pass

        if isinstance(update, Update) and update.effective_message:
            await update.effective_message.reply_text(
                "âŒ ××™×¨×¢×” ×©×’×™××”. ×× × × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."
            )
    
    async def start(self):
        """×”×¤×¢×œ×ª ×”×‘×•×˜"""
        logger.info("××ª×—×™×œ ××ª ×”×‘×•×˜...")
        await self.application.initialize()
        await self.application.start()
        await self.application.updater.start_polling()
        
        logger.info("×”×‘×•×˜ ×¤×•×¢×œ! ×œ×—×¥ Ctrl+C ×œ×”×¤×¡×§×”.")
    
    async def stop(self):
        """×¢×¦×™×¨×ª ×”×‘×•×˜"""
        logger.info("×¢×•×¦×¨ ××ª ×”×‘×•×˜...")
        await self.application.updater.stop()
        await self.application.stop()
        await self.application.shutdown()
        
        # ×©×—×¨×•×¨ × ×¢×™×œ×” ×•×¡×’×™×¨×ª ×—×™×‘×•×¨ ×œ××¡×“ × ×ª×•× ×™×
        try:
            cleanup_mongo_lock()
        except Exception:
            pass
        db.close()
        
        logger.info("×”×‘×•×˜ × ×¢×¦×¨.")

def signal_handler(signum, frame):
    """×˜×™×¤×•×œ ×‘×¡×™×’× ×œ×™ ×¢×¦×™×¨×”"""
    logger.info(f"×”×ª×§×‘×œ ×¡×™×’× ×œ {signum}, ×¢×•×¦×¨ ××ª ×”×‘×•×˜...")
    sys.exit(0)

# ---------------------------------------------------------------------------
# Helper to register the basic command handlers with the Application instance.
# ---------------------------------------------------------------------------


def setup_handlers(application: Application, db_manager):  # noqa: D401
    """Register basic command handlers required for the bot to operate."""

    async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):  # noqa: D401
        user_id = update.effective_user.id
        username = update.effective_user.username
        
        # ×©××•×¨ ××©×ª××© ×‘××¡×“ × ×ª×•× ×™× (INSERT OR IGNORE)
        db_manager.save_user(user_id, username)
        
        reporter.report_activity(user_id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×”×’×™×¢ ××”-Web App ××• ×¨×•×¦×” ×œ×”×•×¡×™×£ ×§×•×‘×¥
        if context.args and len(context.args) > 0:
            if context.args[0] == "add_file":
                # ×”××©×ª××© ×¨×•×¦×” ×œ×”×•×¡×™×£ ×§×•×‘×¥ ×—×“×©
                reply_markup = ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
                await update.message.reply_text(
                    "ğŸ“ <b>×”×•×¡×¤×ª ×§×•×‘×¥ ×—×“×©</b>\n\n"
                    "×©×œ×— ×œ×™ ×§×•×‘×¥ ×§×•×“ ××• ×˜×§×¡×˜ ×›×“×™ ×œ×©××•×¨ ××•×ª×•.\n"
                    "××¤×©×¨ ×œ×©×œ×•×—:\n"
                    "â€¢ ×§×•×‘×¥ ×‘×•×“×“ ××• ××¡×¤×¨ ×§×‘×¦×™×\n"
                    "â€¢ ×§×•×‘×¥ ZIP ×¢× ××¡×¤×¨ ×§×‘×¦×™×\n"
                    "â€¢ ×”×•×“×¢×ª ×˜×§×¡×˜ ×¢× ×§×•×“\n\n"
                    "ğŸ’¡ ×˜×™×¤: ××¤×©×¨ ×œ×”×•×¡×™×£ ×ª×™××•×¨ ×œ×§×•×‘×¥ ×‘×›×™×ª×•×‘ (caption)",
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.HTML
                )
                return
            elif context.args[0] == "webapp_login":
                # ×™×¦×™×¨×ª ×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª ××™×©×™
                webapp_url = os.getenv('WEBAPP_URL', 'https://code-keeper-webapp.onrender.com')
                
                # ×™×¦×™×¨×ª ×˜×•×§×Ÿ ×–×× ×™ ×œ××™××•×ª (××¤×©×¨ ×œ×”×©×ª××© ×‘-JWT ××• hash ×¤×©×•×˜)
                import hashlib
                import time
                timestamp = int(time.time())
                secret = os.getenv('SECRET_KEY', 'dev-secret-key')
                token_data = f"{user_id}:{timestamp}:{secret}"
                auth_token = hashlib.sha256(token_data.encode()).hexdigest()[:32]
                
                # ×©××™×¨×ª ×”×˜×•×§×Ÿ ×‘××¡×“ × ×ª×•× ×™× ×¢× ×ª×•×§×£ ×©×œ 5 ×“×§×•×ª
                db = db_manager.get_db()
                db.webapp_tokens.insert_one({
                    'token': auth_token,
                    'user_id': user_id,
                    'username': username,
                    'created_at': datetime.now(timezone.utc),
                    'expires_at': datetime.now(timezone.utc) + timedelta(minutes=5)
                })
                
                # ×™×¦×™×¨×ª ×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª
                login_url = f"{webapp_url}/auth/token?token={auth_token}&user_id={user_id}"
                
                keyboard = [
                    [InlineKeyboardButton("ğŸ” ×”×ª×—×‘×¨ ×œ-Web App", url=login_url)],
                    [InlineKeyboardButton("ğŸŒ ×¤×ª×— ××ª ×”-Web App", url=webapp_url)]
                ]
                reply_markup_inline = InlineKeyboardMarkup(keyboard)
                
                await update.message.reply_text(
                    "ğŸ” <b>×§×™×©×•×¨ ×”×ª×—×‘×¨×•×ª ××™×©×™ ×œ-Web App</b>\n\n"
                    "×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×œ××˜×” ×›×“×™ ×œ×”×ª×—×‘×¨:\n\n"
                    "âš ï¸ <i>×”×§×™×©×•×¨ ×ª×§×£ ×œ-5 ×“×§×•×ª ×‘×œ×‘×“ ××˜×¢××™ ××‘×˜×—×”</i>",
                    reply_markup=reply_markup_inline,
                    parse_mode=ParseMode.HTML
                )
                return
        
        reply_markup = ReplyKeyboardMarkup(MAIN_KEYBOARD, resize_keyboard=True)
        await update.message.reply_text(
            "ğŸ‘‹ ×©×œ×•×! ×”×‘×•×˜ ××•×›×Ÿ ×œ×©×™××•×©.\n\n"
            "ğŸ”§ ×œ×›×œ ×ª×§×œ×” ×‘×‘×•×˜ × × ×œ×©×œ×•×— ×”×•×“×¢×” ×œ-@moominAmir", 
            reply_markup=reply_markup
        )

    async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):  # noqa: D401
        reporter.report_activity(update.effective_user.id)
        await log_user_activity(update, context)  # ×”×•×¡×¤×ª ×¨×™×©×•× ××©×ª××© ×œ×¡×˜×˜×™×¡×˜×™×§×•×ª
        await update.message.reply_text(
            "â„¹ï¸ ×”×©×ª××© ×‘/start ×›×“×™ ×œ×”×ª×—×™×œ.\n\n"
            "ğŸ”§ ×œ×›×œ ×ª×§×œ×” ×‘×‘×•×˜ × × ×œ×©×œ×•×— ×”×•×“×¢×” ×œ-@moominAmir"
        )

    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))


# ---------------------------------------------------------------------------
# New lock-free main
# ---------------------------------------------------------------------------
def main() -> None:
    """
    Initializes and runs the bot after acquiring a lock.
    """
    try:
        # Initialize database first
        global db
        db = DatabaseManager()
        
        # MongoDB connection and lock management
        if not manage_mongo_lock():
            logger.warning("Another bot instance is already running. Exiting gracefully.")
            # ×™×¦×™××” × ×§×™×™×” ×œ×œ× ×©×’×™××”
            sys.exit(0)

        # --- ×”××©×š ×”×§×•×“ ×”×§×™×™× ×©×œ×š ---
        logger.info("Lock acquired. Initializing CodeKeeperBot...")
        
        bot = CodeKeeperBot()
        
        logger.info("Bot is starting to poll...")
        bot.application.run_polling(drop_pending_updates=True)
        
    except Exception as e:
        logger.error(f"×©×’×™××”: {e}")
        raise
    finally:
        logger.info("Bot polling stopped. Releasing lock and closing database connection.")
        try:
            cleanup_mongo_lock()
        except Exception:
            pass
        if 'db' in globals():
            db.close_connection()


# A minimal post_init stub to comply with the PTB builder chain
async def setup_bot_data(application: Application) -> None:  # noqa: D401
    """A post_init function to setup application-wide data."""
    # ××—×™×§×ª ×›×œ ×”×¤×§×•×“×•×ª ×”×¦×™×‘×•×¨×™×•×ª (××™×Ÿ ×œ×”×’×“×™×¨ /share /share_help â€” ×©×™×ª×•×£ ×“×¨×š ×”×›×¤×ª×•×¨×™×)
    await application.bot.delete_my_commands()
    logger.info("âœ… Public commands cleared (no /share, /share_help)")
    
    # ×”×’×“×¨×ª ×¤×§×•×“×ª stats ×¨×§ ×œ×× ×”×œ (×××™×¨ ×‘×™×¨×•×Ÿ)
    AMIR_ID = 6865105071  # ×”-ID ×©×œ ×××™×¨ ×‘×™×¨×•×Ÿ
    
    try:
        # ×”×’×“×¨ ×¨×§ ××ª ×¤×§×•×“×ª stats ×œ×××™×¨
        await application.bot.set_my_commands(
            commands=[
                BotCommand("stats", "ğŸ“Š ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×™××•×©"),
            ],
            scope=BotCommandScopeChat(chat_id=AMIR_ID)
        )
        logger.info(f"âœ… Commands set for Amir (ID: {AMIR_ID}): stats only")
    except Exception as e:
        logger.error(f"âš ï¸ Error setting admin commands: {e}")
    
    # ×”×¤×¢×œ×ª ×©×¨×ª ×§×˜×Ÿ ×œ-/health ×•-/share/<id> â€” ×›×‘×•×™ ×›×‘×¨×™×¨×ª ××—×“×œ
    enable_internal_web = str(os.getenv('ENABLE_INTERNAL_SHARE_WEB', 'false')).lower() == 'true'
    if enable_internal_web and config.PUBLIC_BASE_URL:
        try:
            from services.webserver import create_app
            aiohttp_app = create_app()
            async def _start_web_job(context: ContextTypes.DEFAULT_TYPE):
                runner = web.AppRunner(aiohttp_app)
                await runner.setup()
                port = int(os.getenv("PORT", "10000"))
                site = web.TCPSite(runner, host="0.0.0.0", port=port)
                await site.start()
                logger.info(f"ğŸŒ Internal web server started on :{port}")
            # ×œ×”×¨×™×¥ ××—×¨×™ ×©×”××¤×œ×™×§×¦×™×” ×”×ª×—×™×œ×”, ×›×“×™ ×œ×”×™×× ×¢ ×-PTBUserWarning
            application.job_queue.run_once(_start_web_job, when=0)
        except Exception as e:
            logger.error(f"âš ï¸ Failed to start internal web server: {e}")
    else:
        logger.info("â„¹ï¸ Skipping internal web server (disabled or missing PUBLIC_BASE_URL)")

    # Reschedule Google Drive backup jobs for all users with an active schedule
    try:
        async def _reschedule_drive_jobs(context: ContextTypes.DEFAULT_TYPE):
            try:
                drive_handler = context.application.bot_data.get('drive_handler')
                if not drive_handler:
                    return
                # Access users collection directly to find users with drive schedules
                users_coll = db.db.users if getattr(db, 'db', None) else None
                if users_coll is None:
                    return
                sched_keys = {"daily", "every3", "weekly", "biweekly", "monthly"}
                cursor = None
                try:
                    cursor = users_coll.find({"drive_prefs.schedule": {"$in": list(sched_keys)}})
                except Exception:
                    cursor = []
                for doc in cursor:
                    try:
                        uid = int(doc.get("user_id") or 0)
                        if not uid:
                            continue
                        prefs = doc.get("drive_prefs") or {}
                        key = prefs.get("schedule")
                        if key in sched_keys:
                            # Ensure a repeating job exists and is aligned to the next planned time
                            await drive_handler._ensure_schedule_job(context, uid, key)  # type: ignore[attr-defined]
                    except Exception:
                        continue
            except Exception:
                pass
        # Run once shortly after startup to restore jobs after restarts/deploys
        application.job_queue.run_once(_reschedule_drive_jobs, when=1)
    except Exception:
        logger.warning("Failed to schedule Drive jobs rescan on startup")

if __name__ == "__main__":
    main()
